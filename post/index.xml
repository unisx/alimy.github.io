<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Posts on 北 野 </title>
      <generator uri="https://gohugo.io">Hugo</generator>
    <link>http://alimy.me/post/</link>
    
    
    <copyright>&amp;copy;2018, Alimy; all rights reserved.</copyright>
    <updated>Sun, 25 Nov 2018 07:57:00 CST</updated>
    
    <item>
      <title>sshuttle：不需配置的 VPN</title>
      <link>http://alimy.me/post/dev_201811250757/</link>
      <pubDate>Sun, 25 Nov 2018 07:57:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201811250757/</guid>
      <description>&lt;p&gt;sshuttle 被其作者称为 “穷人的 VPN”（A poor man’s instant VPN），甚至不需要远端服务器的 root 权限就可以用（只需要一个普通 SSH 帐号），和在 Mac/Linux 客户端直接用 ssh -D 的方式有点类似。如果不想花钱买 VPN，又懒得自己在 VPS 上安装和设置复杂的 VPN 服务，又不想用 ssh -D 这么朴素的技巧的话可以试一下这个 sshuttle，按照作者的说法 sshuttle 比 sshd -D 的方式快一点，因为 It’s just data-over-TCP，而不是 TCP-over-TCP，TCP-over-TCP 的方式会带来不必要的性能问题，因为 TCP 本身就是可靠传输协议，保证了包的有序性和无差错，并确保包被接受，如果有包丢失的话 TCP 协议可以自己立即重传弥补，所以没必要两层都 TCP，一层 TCP 就比较安全了。&lt;/p&gt;

&lt;p&gt;sshuttle 的用法很简单，在客户端下载和运行就可以了（需要有 Python 的支持），无需在服务器端做任何配置（但是需要一个 ssh 帐号和 Python 支持）：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/sshuttle/sshuttle
$ cd sshuttle
$ sudo ./setup.py install
$ sshuttle -r username@sshserver 0.0.0.0/0 -vv
Starting sshuttle proxy.
[local sudo] Password: 
firewall manager: Starting firewall with Python version 2.7.15
firewall manager: ready method name nat.
IPv6 enabled: False
UDP enabled: False
DNS enabled: False
User enabled: False
Binding redirector: 12300 12299
TCP redirector listening on (&#39;127.0.0.1&#39;, 12299).
TCP redirector listening with &amp;lt;socket._socketobject object at 0x7f5eb68b1c90&amp;gt;.
Starting client with Python version 2.7.15
c : connecting to server...
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;(备注: 原文的链接在 &lt;a href=&#34;https://www.vpsee.com/2011/05/sshuttle-a-simple-instant-vpn/&#34; title=&#34;sshuttle as vpn&#34;&gt;&lt;em&gt;这里&lt;/em&gt;&lt;/a&gt; )&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AppArmor的前世今生和基本使用</title>
      <link>http://alimy.me/post/dev_201811171435/</link>
      <pubDate>Sat, 17 Nov 2018 14:35:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201811171435/</guid>
      <description>&lt;h4 id=&#34;一-mac和dac-一些前置知识&#34;&gt;一：MAC和DAC (一些前置知识)&lt;/h4&gt;

&lt;p&gt;DAC(Discretionary Access Control)，自主访问控制，是最常用的一类访问控制机制，意思为主体（文件所有者）可以自主指定系统中其它用户对其文件的所有权，最典型的就是Linux的&amp;rdquo;拥有者/同组用户/其他&amp;rdquo;。这种方式虽然为用户提供了很大的灵活性，但是缺乏必要的安全性&lt;/p&gt;

&lt;p&gt;MAC(Mandatory Access Control)，强制访问控制,在这种机制下，系统中的每一个进程，每一个文件，每一个IPC主体都被管理员按照严格的规则设置了相应的安全属性，不能被用户和其它直接或间接的修改。&lt;/p&gt;

&lt;h4 id=&#34;二-apparmor-https-gitlab-com-apparmor-apparmor-apparmor-in-gitlab&#34;&gt;二：&lt;a href=&#34;https://gitlab.com/apparmor/apparmor&#34; title=&#34;AppArmor in GitLab&#34;&gt;AppArmor&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;由于SELinux使用复杂，适用于对安全要求特别高的企业或者组织，为了简化操作，就推出了AppArmor，所以可以说AppArmor脱胎于SELinux，但与SELinux基于角色的MAC不同的是，AppArmor是与程序绑定的基于路径的MAC，也就是说如果路径发生改变，策略就会失效。一般的Linux的系统，都会内置以上两种MAC其中的一种，这也意味着，你需要对文件（其它）进行操作，你需要同时通过DAC和 MAC的检测。&lt;/p&gt;

&lt;p&gt;AppArmor有两种工作模式：enforcement、complain/learning&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Enforcement – 在这种模式下，配置文件里列出的限制条件都会得到执行，并且对于违反这些限制条件的程序会进行日志记录。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Complain – 在这种模式下，配置文件里的限制条件不会得到执行，AppArmor只是对程序的行为进行记录。例如程序可以写一个在配置文件里注明只读的文件，但AppArmor不会对程序的行为进行限制，只是进行记录。这种模式也叫学习模式，如果某个程序的行为不符合其配置文件的限制，可以将其行为记录到系统日志，并且可以根据程序的行为，将日志转换成配置文件。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AppArmor可以对程序进行多方面的限制，详细可以看官方文档，这里只提供几个基本的例子：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;文件系统的访问控制   例：  /home/Desktop/a.c rw 表示程序可以对/home/Desktop/a.c 进行读和写。&lt;/li&gt;
&lt;li&gt;资源限制   例： set rlimit as&amp;lt;=1M ，表示该程序可以使用的虚拟内存小于等于1M&lt;/li&gt;
&lt;li&gt;访问网络   例： network inet tcp ,表示该程序可以在IPV4的情况下使用TCP协议 　&lt;/li&gt;
&lt;li&gt;capability条目 例：capability setgid，表示程序进行setgid操作。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h4 id=&#34;三-基本使用&#34;&gt;三：基本使用&lt;/h4&gt;

&lt;p&gt;ubuntu自带AppArmor，所以以ubuntu14.04为例。
最好先安装了apparmor的管理工具套装：apt-get install apparmor-utils&lt;/p&gt;

&lt;p&gt;测试程序源码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include&amp;lt;stdio.h&amp;gt;  
#include &amp;lt;string.h&amp;gt;  
int main(int argc, char *argv[])  
{  
 　　FILE *f;  
 　　int nn, i;   char ch;   
 　　if(3 == argc){   
  　　　　f = fopen(argv[1], &amp;quot;w&amp;quot;);   
  　 if(f == NULL){                          printf(&amp;quot;Open file %s with write ERROR\n&amp;quot;, argv[1]);  
   　　return 2;  
　　　}   
  　nn = strlen(argv[2]);   
   i = 0;   
   while(i &amp;lt; nn){   
   　　fputc(argv[2][i], f);  
   　　++i; 
  　}  
  fclose(f); 
  }else if(argc == 2){  
  　　f = fopen(argv[1], &amp;quot;r&amp;quot;);  
  　　if(NULL == f){  
   　　　　printf(&amp;quot;Open file %s with read ERROR\n&amp;quot;, argv[1]);  
   　　　　return 2;  
  　　}   
  　　while((ch=fgetc(f)) != EOF){   
   　　　　printf(&amp;quot;%c&amp;quot;, ch);  
 　　 }   
  　　printf(&amp;quot;\n&amp;quot;); 
  　　fclose(f); 
 }else{ 
  　　printf(&amp;quot;Usage: test file **\n&amp;quot;);   
  　　return 3;  
 } 
 
　　 return 0;  
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;基本功能是对，文件进行读写，使用如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;　$　./test a.c &amp;quot;hello,world&amp;quot;  #进行写
　$　./test a.c  #进行读
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以根据 aa-genprof 生成配置文件，生成的文件在/etc/apparmor.d下，文件名为home.jdchen.test&lt;/p&gt;

&lt;p&gt;生成的文件如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Last Modified: Fri Nov 11 03:54:40 2016
#include &amp;lt;tunables/global&amp;gt;

/home/jdchen/test {
  #include &amp;lt;abstractions/base&amp;gt;


}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于apparmor采取类似于白名单的机制，所以不能进行任何操作。
现在给配置文件添加可写的权限并重新加载。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Last Modified: Fri Nov 11 03:54:40 2016
#include &amp;lt;tunables/global&amp;gt;

/home/jdchen/test {
  #include &amp;lt;abstractions/base&amp;gt;
    /home/jdchen/a.c w，

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后介绍几个命令：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ Start : sudo /etc/init.d/apparmor start   #启动
$ Stop : sudo /etc/init.d/apparmor stop   #停止
$ reload: sudo /etc/init.d/apparmor reload 重新加载
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在修改配置之后，需要重载：&lt;/p&gt;

&lt;p&gt;可以试着查看一下日志，节选：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ov 11 04:23:53 ubuntu kernel: [ 2419.881291] audit_printk_skb: 15 callbacks suppressed
Nov 11 04:23:53 ubuntu kernel: [ 2419.881306] audit: type=1400 audit(1478867033.872:204): apparmor=&amp;quot;DENIED&amp;quot; operation=&amp;quot;open&amp;quot; profile=&amp;quot;/home/jdchen/test&amp;quot; name=&amp;quot;/home/jdchen/a.c&amp;quot; pid=4108 comm=&amp;quot;test&amp;quot; requested_mask=&amp;quot;r&amp;quot; denied_mask=&amp;quot;r&amp;quot; fsuid=0 ouid=0
Nov 11 04:24:07 ubuntu kernel: [ 2433.212034] audit: type=1400 audit(1478867047.204:205): apparmor=&amp;quot;DENIED&amp;quot; operation=&amp;quot;open&amp;quot; profile=&amp;quot;/home/jdchen/test&amp;quot; name=&amp;quot;/home/jdchen/a.c&amp;quot; pid=4111 comm=&amp;quot;test&amp;quot; requested_mask=&amp;quot;r&amp;quot; denied_mask=&amp;quot;r&amp;quot; fsuid=0 ouid=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果不需要配置，可以直接将配置文件删除。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;(备注: 原文的链接在 &lt;a href=&#34;https://www.cnblogs.com/0xJDchen/p/6055531.html&#34; title=&#34;Apparmor的前世今生和基本使用&#34;&gt;&lt;em&gt;这里&lt;/em&gt;&lt;/a&gt; )&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Athens:香港服务器Docker部署</title>
      <link>http://alimy.me/post/dev_201811111946/</link>
      <pubDate>Sun, 11 Nov 2018 19:46:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201811111946/</guid>
      <description>&lt;h4 id=&#34;源起&#34;&gt;源起&lt;/h4&gt;

&lt;p&gt;go1.11开始加入module功能支持GOPROXY，解决go依赖包下载问题(你懂的！),Athens应运而生。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.gomods.io/&#34; title=&#34;Athens&#34;&gt;官网介绍&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;Athens is a project building on top of vgo (or go1.11+) trying to bring dependencies closer to you so you can count on repeatable builds even at a time when VCS is down.&lt;/p&gt;

&lt;p&gt;The big goal of Athens is to provide a new place where dependencies — not code — live. Dependencies are immutable blobs of code and associated metadata that come from Github. They live in storage that Athens controls.&lt;/p&gt;

&lt;h4 id=&#34;docker部署&#34;&gt;Docker部署&lt;/h4&gt;

&lt;p&gt;使用Docker进行部署,官方镜像&lt;a href=&#34;https://hub.docker.com/r/gomods/proxy/&#34; title=&#34;Athens&#39;s docker image&#34;&gt;gomods/proxy:latest&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ docker volume create data-athens
$ docker run -d --name athens-proxy --restart always -p 3000:3000 \
    -v data-athens:/var/lib/athens \
    -e ATHENS_DISK_STORAGE_ROOT=/var/lib/athens \ 
    -e ATHENS_STORAGE_TYPE=disk \
    gomods/proxy:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h4 id=&#34;use-memory-backend-defualt&#34;&gt;Use Memory Backend (Defualt)&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;$ docker run -d --name athens-proxy --restart always -p 3000:3000 gomods/proxy:latest
$ docker logs -f athens-proxy # display logs
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Hello, Rustacean</title>
      <link>http://alimy.me/post/day_2018090119142/</link>
      <pubDate>Sat, 01 Sep 2018 19:42:00 CST</pubDate>
      
      <guid>http://alimy.me/post/day_2018090119142/</guid>
      <description>&lt;pre&gt;&lt;code&gt;fn main() {
    let greetings = [&amp;quot;Hello&amp;quot;, &amp;quot;Hola&amp;quot;, &amp;quot;Bonjour&amp;quot;,
                     &amp;quot;Ciao&amp;quot;, &amp;quot;こんにちは&amp;quot;, &amp;quot;안녕하세요&amp;quot;,
                     &amp;quot;Cześć&amp;quot;, &amp;quot;Olá&amp;quot;, &amp;quot;Здравствуйте&amp;quot;,
                     &amp;quot;Chào bạn&amp;quot;, &amp;quot;您好&amp;quot;, &amp;quot;Hallo&amp;quot;,
                     &amp;quot;Hej&amp;quot;, &amp;quot;Ahoj&amp;quot;, &amp;quot;سلام&amp;quot;,&amp;quot;สวัสดี&amp;quot;];

    for (num, greeting) in greetings.iter().enumerate() {
        print!(&amp;quot;{} : &amp;quot;, greeting);
        match num {
            0 =&amp;gt;  println!(&amp;quot;This code is editable and runnable!&amp;quot;),
            1 =&amp;gt;  println!(&amp;quot;¡Este código es editable y ejecutable!&amp;quot;),
            2 =&amp;gt;  println!(&amp;quot;Ce code est modifiable et exécutable !&amp;quot;),
            3 =&amp;gt;  println!(&amp;quot;Questo codice è modificabile ed eseguibile!&amp;quot;),
            4 =&amp;gt;  println!(&amp;quot;このコードは編集して実行出来ます！&amp;quot;),
            5 =&amp;gt;  println!(&amp;quot;여기에서 코드를 수정하고 실행할 수 있습니다!&amp;quot;),
            6 =&amp;gt;  println!(&amp;quot;Ten kod można edytować oraz uruchomić!&amp;quot;),
            7 =&amp;gt;  println!(&amp;quot;Este código é editável e executável!&amp;quot;),
            8 =&amp;gt;  println!(&amp;quot;Этот код можно отредактировать и запустить!&amp;quot;),
            9 =&amp;gt;  println!(&amp;quot;Bạn có thể edit và run code trực tiếp!&amp;quot;),
            10 =&amp;gt; println!(&amp;quot;这段代码是可以编辑并且能够运行的！&amp;quot;),
            11 =&amp;gt; println!(&amp;quot;Dieser Code kann bearbeitet und ausgeführt werden!&amp;quot;),
            12 =&amp;gt; println!(&amp;quot;Den här koden kan redigeras och köras!&amp;quot;),
            13 =&amp;gt; println!(&amp;quot;Tento kód můžete upravit a spustit&amp;quot;),
            14 =&amp;gt; println!(&amp;quot;این کد قابلیت ویرایش و اجرا دارد!&amp;quot;),
            15 =&amp;gt; println!(&amp;quot;โค้ดนี้สามารถแก้ไขได้และรันได้&amp;quot;),
            _ =&amp;gt;  {},
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;没错，今天开始，正式入坑&lt;a href=&#34;https://www.rust-lang.org&#34; title=&#34;Rust official site&#34;&gt;&lt;strong&gt;Rust&lt;/strong&gt;&lt;/a&gt;，我要成为&lt;a href=&#34;http://www.rustacean.net/&#34; title=&#34;Hello, crustaceans&#34;&gt;&lt;strong&gt;Rustacean&lt;/strong&gt;&lt;/a&gt;（Rust社区的成员被称为 Rustacean）的一员！我已经是一名Gopher（Golang程序猿的昵称），日常就是使用Go写写bug，研究一下大佬们的代码，然后继续写自个儿的bug，标准的Gopher节奏，WTF～&lt;/p&gt;

&lt;p&gt;话说，&lt;a href=&#34;https://golang.org&#34; title=&#34;Go official site&#34;&gt;&lt;strong&gt;Golang&lt;/strong&gt;&lt;/a&gt;的吉祥物是Gopher（囊地鼠），陆上跑地欢；Rust的吉祥物是Crab（螃蟹），海里游地慌；巧合吗，很有意思！既如此，已经入坑了陆上跑地欢的&lt;code&gt;Go&lt;/code&gt;，再入手个海里游地慌的&lt;code&gt;Rust&lt;/code&gt;，又有何妨，乐哉!似乎还有一个&lt;code&gt;Swift&lt;/code&gt;，吉祥物是天上飞的雨燕， 也是计划入手的一门语言，但不是现在（项目暂时没用上,不急）， 到时候就海陆空全齐了， 哈哈哈～&lt;/p&gt;

&lt;p&gt;欲攻其事，必先善其器，各门语言有他们擅长的使用场景，都有他们各自溜的舞台，项目需要或适合什么语言去构建，自然就要入手去使用，达到最好运行效果！ 学过很多语言，但日常编程用的最多的还是Go和Java， 嗯哼， 之所以还入手Rust语言，除了项目用的上，更简单的原因就是：看上了&lt;a href=&#34;https://github.com/tikv/tikv&#34; title=&#34;TikV in GitHub&#34;&gt;&lt;strong&gt;TiKV&lt;/strong&gt;&lt;/a&gt; ~&lt;em&gt;So Easy To Nice&lt;/em&gt;~&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SRE:3节点部署TiKV用于测试功能</title>
      <link>http://alimy.me/post/dev_201808191316/</link>
      <pubDate>Sun, 19 Aug 2018 13:16:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201808191316/</guid>
      <description>&lt;h4 id=&#34;源起&#34;&gt;源起&lt;/h4&gt;

&lt;p&gt;闲置几台屌丝版腾讯云服务器（2 core &lt;code&gt;CPU&lt;/code&gt; 4GB &lt;code&gt;Memory&lt;/code&gt; 40GB &lt;code&gt;Disk&lt;/code&gt;)，难得清闲，用其中的3台部署一套TiKV用于测试功能和代码研究。&lt;/p&gt;

&lt;h4 id=&#34;节点分布&#34;&gt;节点分布&lt;/h4&gt;

&lt;p&gt;使用Docker进行部署,官方镜像pingcap/pd:v2.0.6、pingcap/tikv:v2.0.6&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;|    Name   |   Host IP   |  Services  |  Docker Volume  |  Data Path  |
| Node1(TB) | 172.22.0.6  |    PD1     |     pd-data     |    /data    |
| Node2(TD) | 172.22.0.10 |    PD2     |     pd-data     |    /data    |
| Node3(TE) | 172.22.0.15 |    PD3     |     pd-data     |    /data    |
| Node1(TB) | 172.22.0.6  |   TiKV1    |     tikv-data   |    /data    |
| Node2(TD) | 172.22.0.10 |   TiKV2    |     tikv-data   |    /data    |
| Node3(TE) | 172.22.0.15 |   TiKV3    |     tikv-data   |    /data    |
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h4 id=&#34;准备工作&#34;&gt;准备工作&lt;/h4&gt;

&lt;p&gt;三节点（Node1/Node2/Node3)都执行&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo docker pull pingcap/pd:v2.0.6  
sudo docker pull pingcap/tikv:v2.0.6  
sudo docker volume create pd-data  
sudo docker volume create tikv-data

export TBIP=&amp;quot;172.21.0.6&amp;quot;
export TDIP=&amp;quot;172.21.0.10&amp;quot;
export TEIP=&amp;quot;172.21.0.15&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;部署pd&#34;&gt;部署PD&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;In Node1(TB)&amp;gt;：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run -d --restart=always --name pd1 \
-p 2379:2379 \
-p 2380:2380 \
-v pd-data:/data \
pingcap/pd:v2.0.6 \
--name=&amp;quot;pd1&amp;quot; \
--data-dir=&amp;quot;/data/pd1&amp;quot; \
--client-urls=&amp;quot;http://0.0.0.0:2379&amp;quot; \
--advertise-client-urls=&amp;quot;http://${TBIP}:2379&amp;quot; \
--peer-urls=&amp;quot;http://0.0.0.0:2380&amp;quot; \
--advertise-peer-urls=&amp;quot;http://${TBIP}:2380&amp;quot; \
--initial-cluster=&amp;quot;pd1=http://${TBIP}:2380,pd2=http://${TDIP}:2380,pd3=http://${TEIP}:2380&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;In Node2(TD)&amp;gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run -d --restart=always --name pd2 \
-p 2379:2379 \
-p 2380:2380 \
-v pd-data:/data \
pingcap/pd:v2.0.6 \
--name=&amp;quot;pd2&amp;quot; \
--data-dir=&amp;quot;/data/pd2&amp;quot; \
--client-urls=&amp;quot;http://0.0.0.0:2379&amp;quot; \
--advertise-client-urls=&amp;quot;http://${TDIP}:2379&amp;quot; \
--peer-urls=&amp;quot;http://0.0.0.0:2380&amp;quot; \
--advertise-peer-urls=&amp;quot;http://${TDIP}:2380&amp;quot; \
--initial-cluster=&amp;quot;pd1=http://${TBIP}:2380,pd2=http://${TDIP}:2380,pd3=http://${TEIP}:2380&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;In Node3(TE)&amp;gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run -d --restart=always --name pd3 \
-p 2379:2379 \
-p 2380:2380 \
-v pd-data:/data \
pingcap/pd:v2.0.6 \
--name=&amp;quot;pd3&amp;quot; \
--data-dir=&amp;quot;/data/pd3&amp;quot; \
--client-urls=&amp;quot;http://0.0.0.0:2379&amp;quot; \
--advertise-client-urls=&amp;quot;http://${TEIP}:2379&amp;quot; \
--peer-urls=&amp;quot;http://0.0.0.0:2380&amp;quot; \
--advertise-peer-urls=&amp;quot;http://${TEIP}:2380&amp;quot; \
--initial-cluster=&amp;quot;pd1=http://${TBIP}:2380,pd2=http://${TDIP}:2380,pd3=http://${TEIP}:2380&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;部署tikv&#34;&gt;部署TiKV&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;In Node1(TB)&amp;gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run -d --restart=always --name tikv1 \
--ulimit nofile=82920:82920 \
-p 20160:20160 \
-v tikv-data:/data \
pingcap/tikv:v2.0.6 \
--addr=&amp;quot;0.0.0.0:20160&amp;quot; \
--advertise-addr=&amp;quot;${TBIP}:20160&amp;quot; \
--data-dir=&amp;quot;/data/tikv1&amp;quot; \
--pd=&amp;quot;${TBIP}:2379,${TDIP}:2379,${TEIP}:2379&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;In Node2(TD)&amp;gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run -d --restart=always --name tikv2 \
--ulimit nofile=82920:82920 \
-p 20160:20160 \
-v tikv-data:/data \
pingcap/tikv:v2.0.6 \
--addr=&amp;quot;0.0.0.0:20160&amp;quot; \
--advertise-addr=&amp;quot;${TDIP}:20160&amp;quot; \
--data-dir=&amp;quot;/data/tikv2&amp;quot; \
--pd=&amp;quot;${TBIP}:2379,${TDIP}:2379,${TEIP}:2379&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;In Node3(TE)&amp;gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo docker run -d --restart=always --name tikv3 \
--ulimit nofile=82920:82920 \
-p 20160:20160 \
-v tikv-data:/data \
pingcap/tikv:v2.0.6 \
--addr=&amp;quot;0.0.0.0:20160&amp;quot; \
--advertise-addr=&amp;quot;${TEIP}:20160&amp;quot; \
--data-dir=&amp;quot;/data/tikv3&amp;quot; \
--pd=&amp;quot;${TBIP}:2379,${TDIP}:2379,${TEIP}:2379&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;检验是否部署完成&#34;&gt;检验是否部署完成&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;查看PD的成员 (任意节点中执行)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;curl ${TAIP}:2379/v2/members
或（使用httpie）
http ${TAIP}:2379/v2/members
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;查看TiKV节点 (任意节点中执行)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;curl ${TAIP}:2379/pd/api/v1/stores
或（使用httpie）
http ${TAIP}:2379/pd/api/v1/stores
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;tikv-api-简单使用&#34;&gt;TiKV API 简单使用&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;package main

import (
    &amp;quot;fmt&amp;quot;

    &amp;quot;github.com/pingcap/tidb/config&amp;quot;
    &amp;quot;github.com/pingcap/tidb/store/tikv&amp;quot;
)

func main() {
    cli, err := tikv.NewRawKVClient([]string{&amp;quot;:2379&amp;quot;}, config.Security{})
    if err != nil {
        panic(err)
    }
    defer cli.Close()

    fmt.Printf(&amp;quot;cluster ID: %d\n&amp;quot;, cli.ClusterID())

    key := []byte(&amp;quot;Company&amp;quot;)
    val := []byte(&amp;quot;PingCAP&amp;quot;)

    // put key into tikv
    err = cli.Put(key, val)
    if err != nil {
        panic(err)
    }
    fmt.Printf(&amp;quot;Successfully put %s:%s to tikv\n&amp;quot;, key, val)

    // get key from tikv
    val, err = cli.Get(key)
    if err != nil {
        panic(err)
    }
    fmt.Printf(&amp;quot;found val: %s for key: %s\n&amp;quot;, val, key)

    // delete key from tikv
    err = cli.Delete(key)
    if err != nil {
        panic(err)
    }
    fmt.Printf(&amp;quot;key: %s deleted\n&amp;quot;, key)

    // get key again from tikv
    val, err = cli.Get(key)
    if err != nil {
        panic(err)
    }
    fmt.Printf(&amp;quot;found val: %s for key: %s\n&amp;quot;, val, key)
}

// output:
// INFO[0000] [pd] create pd client with endpoints [192.168.199.113:2379]
// INFO[0000] [pd] leader switches to: http://127.0.0.1:2379, previous:
// INFO[0000] [pd] init cluster id 6554145799874853483
// cluster ID: 6554145799874853483
// Successfully put Company:PingCAP to tikv
// found val: PingCAP for key: Company
// key: Company deleted
// found val:  for key: Company
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;注意要点&#34;&gt;注意要点&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;在部署TiKV时， 如果按官方文档部署， 有的使用环境下会出现因为Docker容器内最大文件打开数小于82920导致启动TiKV服务失败, 需要添加&lt;code&gt;--ulimit nofile=82920:82920&lt;/code&gt;选项使用docker启动TiKV&lt;/li&gt;
&lt;li&gt;PD先部署启动完成后再去部署TiKV&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&#34;https://www.pingcap.com/docs/tikv/deploy-tikv-using-docker/&#34; title=&#34;deploy-tikv-using-docker&#34;&gt;Docker部署TiKV官方文档&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Go modules</title>
      <link>http://alimy.me/post/dev_201807232147/</link>
      <pubDate>Mon, 23 Jul 2018 21:47:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201807232147/</guid>
      <description>&lt;h4 id=&#34;sect-definition&#34;&gt;&amp;sect;Definition&lt;/h4&gt;

&lt;p&gt;A module is a collection of related go packages. Modules are the unit of
source code interchange and versionning.&lt;/p&gt;

&lt;h4 id=&#34;sect-quick-history&#34;&gt;&amp;sect;Quick history&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Go before 1.5: populating &lt;em&gt;GOPATH&lt;/em&gt; with &lt;code&gt;go get&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go 1.5 and after: dependency vendoring is introduced.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/golang/vgo&#34;&gt;vgo&lt;/a&gt; is proposed as a prototype for Go modules support.&lt;/li&gt;
&lt;li&gt;Go 1.11 (beta): &lt;code&gt;vgo&lt;/code&gt; is being merged and refined as &lt;code&gt;go mod&lt;/code&gt; (experimental).&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;sect-terminology&#34;&gt;&amp;sect;Terminology&lt;/h4&gt;

&lt;p&gt;This article refers to recurrent expressions. Let&amp;rsquo;s clarify them:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&amp;ldquo;Module root&amp;rdquo;&lt;/em&gt;: the directory containing the file named &lt;code&gt;go.mod&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&amp;ldquo;Module path&amp;rdquo;&lt;/em&gt;: the import path prefix corresponding to the module root.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;&amp;ldquo;Main module&amp;rdquo;&lt;/em&gt;: the module containing the directory where the &lt;code&gt;go&lt;/code&gt; command
is run.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;sect-module-structure&#34;&gt;&amp;sect;Module structure&lt;/h4&gt;

&lt;p&gt;A module is a tree of Go source files to which is added a file named &lt;em&gt;go.mod&lt;/em&gt;.
It contains the module import name, and the declaration of dependency
requirements, exclusions and replacements. Its content would look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;module my/thing
  
require (
        one/thing v1.3.2
        other/thing v2.5.0 // indirect
        ...
)

exclude (
        bad/thing v0.7.3
)

replace (
        src/thing 1.0.2 =&amp;gt; dst/thing v1.1.0
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
Note that a dependency not directly imported in the module&amp;rsquo;s source code by
an import statement is indentified as &lt;em&gt;indirect&lt;/em&gt; in the file.&lt;/p&gt;

&lt;p&gt;A module can contain other modules, in which case their content is excluded
from the parent module.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://alimy.me/images/post/20180723215300.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Alongside &lt;em&gt;go.mod&lt;/em&gt;, a file named &lt;code&gt;go.sum&lt;/code&gt; may be present. This file retains
cryptographic cheksums of module dependencies, if any. It is used to verify
that cached dependencies meet module requirements.&lt;/p&gt;

&lt;p&gt;A module root can reside &lt;strong&gt;anywhere&lt;/strong&gt; on the filesystem, whatever is the
current &lt;em&gt;GOPATH&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&#34;sect-module-dependencies&#34;&gt;&amp;sect;Module dependencies&lt;/h4&gt;

&lt;p&gt;Dependencies are downloaded and stored in &lt;code&gt;GOPATH/src/mod&lt;/code&gt;. A direct
consequence is that the use of a &lt;em&gt;vendor&lt;/em&gt; directory is now obsolete.&lt;/p&gt;

&lt;p&gt;What does this new structure looks like? Suppose we are working on a module
that depends on &lt;em&gt;github.com/me/lib&lt;/em&gt; at version &lt;em&gt;1.0.0&lt;/em&gt;. For such a case, in
&lt;em&gt;GOPATH/src/mod&lt;/em&gt; we would find:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://alimy.me/images/post/20180723215301.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What we can observe is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Dependencies source trees are placed at the root of this directory, with a
slight change: the import path is suffixed with &lt;code&gt;@version&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Source archives retrieved or built from VCS are stored in the &lt;em&gt;download&lt;/em&gt;
folder.&lt;/li&gt;
&lt;li&gt;VCS data is stored in the &lt;em&gt;vcs&lt;/em&gt; folder.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;sect-enabling-go-modules-support&#34;&gt;&amp;sect;Enabling Go modules support&lt;/h4&gt;

&lt;p&gt;In &lt;em&gt;Go 1.11beta2&lt;/em&gt;, the environment variable &lt;code&gt;GO111MODULE&lt;/code&gt; controls whether
module support is enabled or disabled. It accepts three values: &lt;code&gt;on&lt;/code&gt;, &lt;code&gt;off&lt;/code&gt;,
&lt;code&gt;auto&lt;/code&gt; (default).&lt;/p&gt;

&lt;p&gt;If set to &lt;em&gt;&amp;ldquo;on&amp;rdquo;&lt;/em&gt;, module support is enabled whatever path we are in.&lt;/p&gt;

&lt;p&gt;If set to &lt;em&gt;&amp;ldquo;off&amp;rdquo;&lt;/em&gt;, it is permanently disabled.&lt;/p&gt;

&lt;p&gt;If unset or set to &lt;em&gt;&amp;ldquo;auto&amp;rdquo;&lt;/em&gt;, module support is enabled outside of
&lt;em&gt;GOPATH&lt;/em&gt; only if the current directory is a module root or one of
its subdirectories.&lt;/p&gt;

&lt;h4 id=&#34;sect-integration&#34;&gt;&amp;sect;Integration&lt;/h4&gt;

&lt;p&gt;Go modules are integrated with Go tools, for instance upon invocation of
commands such as &lt;code&gt;go build&lt;/code&gt;, &lt;code&gt;go install&lt;/code&gt;, &lt;code&gt;go run&lt;/code&gt;, &lt;code&gt;go test&lt;/code&gt; appropriate
actions will fire up like populating the cache, creating or updating &lt;em&gt;go.mod&lt;/em&gt;
and &lt;em&gt;go.sum&lt;/em&gt; etc.&lt;/p&gt;

&lt;h4 id=&#34;sect-autoformat&#34;&gt;&amp;sect;Autoformat&lt;/h4&gt;

&lt;p&gt;You should never have to run these commands on your own since they are
invoked by other commands, but for the sake of completeness, let&amp;rsquo;s mention
that &lt;code&gt;go mod -fmt&lt;/code&gt; is the equivalent of &lt;code&gt;go fmt&lt;/code&gt; for &lt;em&gt;go.mod&lt;/em&gt; and &lt;em&gt;go.sum&lt;/em&gt;
files and that &lt;code&gt;go mod -fix&lt;/code&gt; do some smart things in order to keep &lt;em&gt;go.mod&lt;/em&gt;
clean, like:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Rewriting non-canonical version identifiers to semantic versioning form.&lt;/li&gt;
&lt;li&gt;Removing duplicates.&lt;/li&gt;
&lt;li&gt;Updating requirements to reflect exclusions.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;sect-initialization&#34;&gt;&amp;sect;Initialization&lt;/h4&gt;

&lt;p&gt;To create &lt;em&gt;go.mod&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go mod -init
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You may have to pass the command an import path with &lt;code&gt;-module &amp;lt;path&amp;gt;&lt;/code&gt; if the
module root lives outside a VCS.&lt;/p&gt;

&lt;p&gt;For the sake of backward compatibility and in order to ease the transition
process, module creation has support for popular dependency management tools
like &lt;code&gt;dep&lt;/code&gt;, &lt;code&gt;glide&lt;/code&gt;, &lt;code&gt;glock&lt;/code&gt;, &lt;code&gt;godep&lt;/code&gt; and so on.&lt;/p&gt;

&lt;h4 id=&#34;sect-synchronization&#34;&gt;&amp;sect;Synchronization&lt;/h4&gt;

&lt;p&gt;In order to clean up unused dependencies or to fetch new ones, use the sync
option:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go mod -sync
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;sect-adding-excluding-and-replacing-dependencies&#34;&gt;&amp;sect;Adding, excluding and replacing dependencies&lt;/h4&gt;

&lt;p&gt;Two possibilities: either edit &lt;em&gt;go.mod&lt;/em&gt; by hand or use the CLI. The latter
comes with the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# require a new dependency
go mod -require one/thing@version

# drop a requirement
go mod -droprequire one/thing

# exclude a dependency
go mod -exclude bad/thing@version

# drop an exclusion
go mod -dropexclude bad/thing@version

# replace a dependency
go mod -replace src/thing@version=dst/thing@version

# drop a replacement
go mod -dropreplace src/thing@version
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;sect-dependency-graph&#34;&gt;&amp;sect;Dependency graph&lt;/h4&gt;

&lt;p&gt;To print the graph of module dependencies:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go mod -graph
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;sect-generating-vendor&#34;&gt;&amp;sect;Generating &lt;em&gt;vendor&lt;/em&gt;&lt;/h4&gt;

&lt;p&gt;If for backward compatibility reasons you need to ship your application with
vendoring, you can generate the &lt;em&gt;vendor&lt;/em&gt; directory from &lt;em&gt;go.mod&lt;/em&gt; thanks to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go mod -vendor
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;sect-getting-help&#34;&gt;&amp;sect;Getting help&lt;/h4&gt;

&lt;p&gt;Don&amp;rsquo;t hesistate to refer to &lt;code&gt;go help mod&lt;/code&gt; and &lt;code&gt;go help modules&lt;/code&gt; for further
details about Go module support!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;(Note: This article’s original links is &lt;a href=&#34;https://systemdump.io/posts/2018-07-22-go-modules&#34; title=&#34;go modules&#34;&gt;&lt;em&gt;here&lt;/em&gt;&lt;/a&gt; )&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Guide: gorilla/mux</title>
      <link>http://alimy.me/post/dev_201807151843/</link>
      <pubDate>Sun, 15 Jul 2018 18:43:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201807151843/</guid>
      <description>&lt;p&gt;The name mux stands for &amp;ldquo;HTTP request multiplexer&amp;rdquo;. Like the standard
&lt;code&gt;http.ServeMux&lt;/code&gt;, &lt;code&gt;mux.Router&lt;/code&gt; matches incoming requests against a list of
registered routes and calls a handler for the route that matches the URL
or other conditions. The main features are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* Requests can be matched based on URL host, path, path prefix, schemes,
  header and query values, HTTP methods or using custom matchers.
* URL hosts, paths and query values can have variables with an optional
  regular expression.
* Registered URLs can be built, or &amp;quot;reversed&amp;quot;, which helps maintaining
  references to resources.
* Routes can be used as subrouters: nested routes are only tested if the
  parent route matches. This is useful to define groups of routes that
  share common conditions like a host, a path prefix or other repeated
  attributes. As a bonus, this optimizes request matching.
* It implements the http.Handler interface so it is compatible with the
  standard http.ServeMux.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s start registering a couple of URL paths and handlers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
  r := mux.NewRouter()
  r.HandleFunc(&amp;quot;/&amp;quot;, HomeHandler)
  r.HandleFunc(&amp;quot;/products&amp;quot;, ProductsHandler)
  r.HandleFunc(&amp;quot;/articles&amp;quot;, ArticlesHandler)
  http.Handle(&amp;quot;/&amp;quot;, r)
  log.Fatal(http.ListenAndServe(&amp;quot;:12345&amp;quot;, nil))
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
Here we register three routes mapping URL paths to handlers. This is
equivalent to how &lt;code&gt;http.HandleFunc()&lt;/code&gt; works: if an incoming request URL matches
one of the paths, the corresponding handler is called passing
&lt;code&gt;(http.ResponseWriter, *http.Request)&lt;/code&gt; as parameters.&lt;/p&gt;

&lt;p&gt;Paths can have variables. They are defined using the format &lt;code&gt;{name}&lt;/code&gt; or
&lt;code&gt;{name:pattern}&lt;/code&gt;. If a regular expression pattern is not defined, the matched
variable will be anything until the next slash. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := mux.NewRouter()
r.HandleFunc(&amp;quot;/products/{key}&amp;quot;, ProductHandler)
r.HandleFunc(&amp;quot;/articles/{category}/&amp;quot;, ArticlesCategoryHandler)
r.HandleFunc(&amp;quot;/articles/{category}/{id:[0-9]+}&amp;quot;, ArticleHandler)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Groups can be used inside patterns, as long as they are non-capturing &lt;code&gt;(?:re)&lt;/code&gt;. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r.HandleFunc(&amp;quot;/articles/{category}/{sort:(?:asc|desc|new)}&amp;quot;, ArticlesCategoryHandler)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The names are used to create a map of route variables which can be retrieved
calling mux.Vars():&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vars := mux.Vars(request)
category := vars[&amp;quot;category&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that if any capturing groups are present, mux will panic() during parsing. To prevent
this, convert any capturing groups to non-capturing, e.g. change&lt;code&gt;&amp;quot;/{sort:(asc|desc)}&amp;quot;&lt;/code&gt; to
&lt;code&gt;&amp;quot;/{sort:(?:asc|desc)}&amp;quot;&lt;/code&gt;. This is a change from prior versions which behaved unpredictably
when capturing groups were present.&lt;/p&gt;

&lt;p&gt;And this is all you need to know about the basic usage. More advanced options
are explained below.&lt;/p&gt;

&lt;p&gt;Routes can also be restricted to a domain or subdomain. Just define a host
pattern to be matched. They can also have variables:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := mux.NewRouter()
// Only matches if domain is &amp;quot;www.example.com&amp;quot;.
r.Host(&amp;quot;www.example.com&amp;quot;)
// Matches a dynamic subdomain.
r.Host(&amp;quot;{subdomain:[a-z]+}.domain.com&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are several other matchers that can be added. To match path prefixes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r.PathPrefix(&amp;quot;/products/&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;or HTTP methods:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r.Methods(&amp;quot;GET&amp;quot;, &amp;quot;POST&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;or URL schemes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r.Schemes(&amp;quot;https&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;or header values:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r.Headers(&amp;quot;X-Requested-With&amp;quot;, &amp;quot;XMLHttpRequest&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;or query values:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r.Queries(&amp;quot;key&amp;quot;, &amp;quot;value&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;or to use a custom matcher function:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r.MatcherFunc(func(r *http.Request, rm *RouteMatch) bool {
    return r.ProtoMajor == 0
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;and finally, it is possible to combine several matchers in a single route:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r.HandleFunc(&amp;quot;/products&amp;quot;, ProductsHandler).
  Host(&amp;quot;www.example.com&amp;quot;).
  Methods(&amp;quot;GET&amp;quot;).
  Schemes(&amp;quot;http&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Setting the same matching conditions again and again can be boring, so we have
a way to group several routes that share the same requirements.
We call it &lt;code&gt;subrouting&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For example, let&amp;rsquo;s say we have several URLs that should only match when the
host is &lt;code&gt;www.example.com&lt;/code&gt;. Create a route for that host and get a &lt;code&gt;subrouter&lt;/code&gt;
from it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := mux.NewRouter()
s := r.Host(&amp;quot;www.example.com&amp;quot;).Subrouter()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then register routes in the subrouter:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;s.HandleFunc(&amp;quot;/products/&amp;quot;, ProductsHandler)
s.HandleFunc(&amp;quot;/products/{key}&amp;quot;, ProductHandler)
s.HandleFunc(&amp;quot;/articles/{category}/{id:[0-9]+}&amp;quot;), ArticleHandler)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The three URL paths we registered above will only be tested if the domain is
&lt;code&gt;www.example.com&lt;/code&gt;, because the subrouter is tested first. This is not
only convenient, but also optimizes request matching. You can create
subrouters combining any attribute matchers accepted by a route.&lt;/p&gt;

&lt;p&gt;Subrouters can be used to create domain or path &lt;code&gt;namespaces&lt;/code&gt;: you define
subrouters in a central place and then parts of the app can register its
paths relatively to a given subrouter.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s one more thing about subroutes. When a subrouter has a path prefix,
the inner routes use it as base for their paths:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := mux.NewRouter()
s := r.PathPrefix(&amp;quot;/products&amp;quot;).Subrouter()
// &amp;quot;/products/&amp;quot;
s.HandleFunc(&amp;quot;/&amp;quot;, ProductsHandler)
// &amp;quot;/products/{key}/&amp;quot;
s.HandleFunc(&amp;quot;/{key}/&amp;quot;, ProductHandler)
// &amp;quot;/products/{key}/details&amp;quot;
s.HandleFunc(&amp;quot;/{key}/details&amp;quot;, ProductDetailsHandler)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that the path provided to &lt;code&gt;PathPrefix()&lt;/code&gt; represents a &amp;ldquo;wildcard&amp;rdquo;: calling
&lt;code&gt;PathPrefix(&amp;quot;/static/&amp;quot;).Handler(...)&lt;/code&gt;means that the handler will be passed any
request that matches&lt;code&gt;&amp;quot;/static/*&amp;quot;&lt;/code&gt;. This makes it easy to serve static files with mux:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func main() {
    var dir string

    flag.StringVar(&amp;amp;dir, &amp;quot;dir&amp;quot;, &amp;quot;.&amp;quot;, &amp;quot;the directory to serve files from. Defaults to the current dir&amp;quot;)
    flag.Parse()
    r := mux.NewRouter()

    // This will serve files under http://localhost:8000/static/&amp;lt;filename&amp;gt;
    r.PathPrefix(&amp;quot;/static/&amp;quot;).Handler(http.StripPrefix(&amp;quot;/static/&amp;quot;, http.FileServer(http.Dir(dir))))

    srv := &amp;amp;http.Server{
        Handler:      r,
        Addr:         &amp;quot;127.0.0.1:8000&amp;quot;,
        // Good practice: enforce timeouts for servers you create!
        WriteTimeout: 15 * time.Second,
        ReadTimeout:  15 * time.Second,
    }

    log.Fatal(srv.ListenAndServe())
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s see how to build registered URLs.&lt;/p&gt;

&lt;p&gt;Routes can be named. All routes that define a name can have their URLs built,
or &amp;ldquo;reversed&amp;rdquo;. We define a name calling &lt;code&gt;Name()&lt;/code&gt; on a route. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := mux.NewRouter()
r.HandleFunc(&amp;quot;/articles/{category}/{id:[0-9]+}&amp;quot;, ArticleHandler).
  Name(&amp;quot;article&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To build a URL, get the route and call the &lt;code&gt;URL()&lt;/code&gt; method, passing a sequence of
&lt;code&gt;key/value&lt;/code&gt; pairs for the route variables. For the previous route, we would do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;url, err := r.Get(&amp;quot;article&amp;quot;).URL(&amp;quot;category&amp;quot;, &amp;quot;technology&amp;quot;, &amp;quot;id&amp;quot;, &amp;quot;42&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;and the result will be a url.URL with the following path:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;/articles/technology/42&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This also works for host and query value variables:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := mux.NewRouter()
r.Host(&amp;quot;{subdomain}.domain.com&amp;quot;).
  Path(&amp;quot;/articles/{category}/{id:[0-9]+}&amp;quot;).
  Queries(&amp;quot;filter&amp;quot;, &amp;quot;{filter}&amp;quot;).
  HandlerFunc(ArticleHandler).
  Name(&amp;quot;article&amp;quot;)

// url.String() will be &amp;quot;http://news.domain.com/articles/technology/42?filter=gorilla&amp;quot;
url, err := r.Get(&amp;quot;article&amp;quot;).URL(&amp;quot;subdomain&amp;quot;, &amp;quot;news&amp;quot;,
                                 &amp;quot;category&amp;quot;, &amp;quot;technology&amp;quot;,
                                 &amp;quot;id&amp;quot;, &amp;quot;42&amp;quot;,
                                 &amp;quot;filter&amp;quot;, &amp;quot;gorilla&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All variables defined in the route are required, and their values must
conform to the corresponding patterns. These requirements guarantee that a
generated URL will always match a registered route &amp;ndash; the only exception is
for explicitly defined &amp;ldquo;build-only&amp;rdquo; routes which never match.&lt;/p&gt;

&lt;p&gt;Regex support also exists for matching Headers within a route. For example, we could do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r.HeadersRegexp(&amp;quot;Content-Type&amp;quot;, &amp;quot;application/(text|json)&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;and the route will match both requests with a Content-Type of &lt;code&gt;application/json&lt;/code&gt; as well as
&lt;code&gt;application/text&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s also a way to build only the URL host or path for a route:
use the methods URLHost() or URLPath() instead. For the previous route,
we would do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// &amp;quot;http://news.domain.com/&amp;quot;
host, err := r.Get(&amp;quot;article&amp;quot;).URLHost(&amp;quot;subdomain&amp;quot;, &amp;quot;news&amp;quot;)

// &amp;quot;/articles/technology/42&amp;quot;
path, err := r.Get(&amp;quot;article&amp;quot;).URLPath(&amp;quot;category&amp;quot;, &amp;quot;technology&amp;quot;, &amp;quot;id&amp;quot;, &amp;quot;42&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And if you use subrouters, host and path defined separately can be built
as well:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := mux.NewRouter()
s := r.Host(&amp;quot;{subdomain}.domain.com&amp;quot;).Subrouter()
s.Path(&amp;quot;/articles/{category}/{id:[0-9]+}&amp;quot;).
  HandlerFunc(ArticleHandler).
  Name(&amp;quot;article&amp;quot;)

// &amp;quot;http://news.domain.com/articles/technology/42&amp;quot;
url, err := r.Get(&amp;quot;article&amp;quot;).URL(&amp;quot;subdomain&amp;quot;, &amp;quot;news&amp;quot;,
                                 &amp;quot;category&amp;quot;, &amp;quot;technology&amp;quot;,
                                 &amp;quot;id&amp;quot;, &amp;quot;42&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mux supports the addition of middlewares to a Router, which are executed in the order they are added if a match is found, including its subrouters. Middlewares are (typically) small pieces of code which take one request, do something with it, and pass it down to another middleware or the final handler. Some common use cases for middleware are request logging, header manipulation, or ResponseWriter hijacking.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type MiddlewareFunc func(http.Handler) http.Handler
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Typically, the returned handler is a closure which does something with the http.ResponseWriter and http.Request passed to it, and then calls the handler passed as parameter to the MiddlewareFunc (closures can access variables from the context where they are created).&lt;/p&gt;

&lt;p&gt;A very basic middleware which logs the URI of the request being handled could be written as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func simpleMw(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        // Do stuff here
        log.Println(r.RequestURI)
        // Call the next handler, which can be another middleware in the chain, or the final handler.
        next.ServeHTTP(w, r)
    })
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Middlewares can be added to a router using &lt;code&gt;Router.Use()&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;r := mux.NewRouter()
r.HandleFunc(&amp;quot;/&amp;quot;, handler)
r.Use(simpleMw)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A more complex authentication middleware, which maps session token to users, could be written as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Define our struct
type authenticationMiddleware struct {
    tokenUsers map[string]string
}

// Initialize it somewhere
func (amw *authenticationMiddleware) Populate() {
    amw.tokenUsers[&amp;quot;00000000&amp;quot;] = &amp;quot;user0&amp;quot;
    amw.tokenUsers[&amp;quot;aaaaaaaa&amp;quot;] = &amp;quot;userA&amp;quot;
    amw.tokenUsers[&amp;quot;05f717e5&amp;quot;] = &amp;quot;randomUser&amp;quot;
    amw.tokenUsers[&amp;quot;deadbeef&amp;quot;] = &amp;quot;user0&amp;quot;
}

// Middleware function, which will be called for each request
func (amw *authenticationMiddleware) Middleware(next http.Handler) http.Handler {
    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
        token := r.Header.Get(&amp;quot;X-Session-Token&amp;quot;)

        if user, found := amw.tokenUsers[token]; found {
            // We found the token in our map
            log.Printf(&amp;quot;Authenticated user %s\n&amp;quot;, user)
            next.ServeHTTP(w, r)
        } else {
            http.Error(w, &amp;quot;Forbidden&amp;quot;, http.StatusForbidden)
        }
    })
}

r := mux.NewRouter()
r.HandleFunc(&amp;quot;/&amp;quot;, handler)

amw := authenticationMiddleware{}
amw.Populate()

r.Use(amw.Middleware)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note: The handler chain will be stopped if your middleware doesn&amp;rsquo;t call &lt;code&gt;next.ServeHTTP()&lt;/code&gt; with the corresponding parameters. This can be used to abort a request if the middleware writer wants to.&lt;/p&gt;

&lt;p&gt;(Origin official document is &lt;a href=&#34;http://www.gorillatoolkit.org/pkg/mux&#34; title=&#34;gorilla/mux document&#34;&gt;&lt;em&gt;Here&lt;/em&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/gorilla/mux&#34; title=&#34;gorilla/mux source code in GitHub&#34;&gt;&lt;em&gt;Source code in GitHub&lt;/em&gt;&lt;/a&gt;)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Docker: 对Docker Remote API进行认证</title>
      <link>http://alimy.me/post/dev_201807012219/</link>
      <pubDate>Sun, 01 Jul 2018 22:19:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201807012219/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;建立证书授权中心&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mkdir /etc/docker
$ cd /etc/docker
$ echo 01 | sudo tee ca.csl
$ sudo openssl genrsa -des3 -out ca-key.pem
$ sudo openssl req -new -x509 -days 365 -key ca-key.pem -out ca.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;创建服务器的证书签名请求和密钥&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ sudo openssl genrsa -des3 -out server-key.pem
$ sudo openssl req -new -key server-key.pem -out server.csr
$ sudo openssl x509 -req -days 365 -in server.csr -CA ca.pem -CAkey ca-key.pem -out server-cert.pem
$ sudo openssl rsa -in server-key.pem -out server-key.pem
$ sudo chmod 0600 /etc/docker/server-key.pem /etc/docker/server-cert.pem /etc/docker/ca-key.pem /etc/docker/ca.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;配置Docker守护进程 (/etc/docker/daemon.json on Linux systems, or C:\ProgramData\docker\config\daemon.json on Windows.)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;debug&amp;quot;: true,
  &amp;quot;tls&amp;quot;: true,
  &amp;quot;tlscacert&amp;quot;: &amp;quot;/etc/docker/ca.pem&amp;quot;,
  &amp;quot;tlscert&amp;quot;: &amp;quot;/etc/docker/server-cert.pem&amp;quot;,
  &amp;quot;tlskey&amp;quot;: &amp;quot;/etc/docker/server-key.pem&amp;quot;,
  &amp;quot;hosts&amp;quot;: [&amp;quot;tcp://&amp;lt;config of CN&amp;gt;:2376&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建客户端证书和密钥&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ sudo openssl genrsa -des3 -out client-key.pem
$ sudo openssl req -new -key client-key.pem -out client.csr
$ echo extendedKeyUsage = clientAuth &amp;gt; extfile.config
$ sudo openssl x509 -req -days 365 -in client.csr -CA ca.pem -CAkey ca-key.pem -out client-cert.pem -extfile extfile.cnf
$ sudo openssl rsa -in client-key.pem -out client-key.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;配置Docker客户端开启认证功能&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ mkdir -p ~/.docker
$ cp ca.pem ~/.docker/ca.pem
$ cp client-key.pem ~/.docker/key.pem
$ cp client-cert.pem ~/.docker/cert.pem
$ chmod 0600 ~/.docker/key.pem ~/.docker/cert.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;测试TLS认证过的连接&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ sudo docker -H=&amp;lt;config of CN&amp;gt;:2376 --tlsverify info
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;可以添加环境变量(~/.bashrc)&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;export DOCKER_HOST=&amp;lt;config of CN&amp;gt;:2376
alias docker=&#39;docker --tlsverify&#39;
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>存储系统: 札记</title>
      <link>http://alimy.me/post/dev_201807011459/</link>
      <pubDate>Sun, 01 Jul 2018 14:59:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201807011459/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.importnew.com/3292.html&#34; title=&#34;Finding a needle in Haystack: Facebook’s photo storage&#34;&gt;经典论文翻译导读之《Finding a needle in Haystack: Facebook’s photo storage》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI4NDMyNTU2Mw==&amp;amp;mid=2247483679&amp;amp;idx=1&amp;amp;sn=584dbd80aa08fa1188627ad725680928&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1208L9z4yXKLW60rPph2ZmMn#rd&#34; title=&#34;微信序列号生成器架构设计及演变&#34;&gt;万亿级调用系统：微信序列号生成器架构设计及演变&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gogs: PR-5322</title>
      <link>http://alimy.me/post/dev_201806301842/</link>
      <pubDate>Sat, 30 Jun 2018 18:42:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201806301842/</guid>
      <description>&lt;h3 id=&#34;add-new-dockerfile-docker-ce-for-docker-ce-v17-06-to-build-gogs-s-docker-image&#34;&gt;Add new Dockerfile.docker-ce for docker-ce(&amp;gt;=v17.06) to build Gogs&amp;rsquo;s docker image&lt;/h3&gt;

&lt;p&gt;Docker-CE can be given to a new build stage by adding &lt;code&gt;AS&lt;/code&gt; name to the&lt;code&gt;FROM&lt;/code&gt; instruction sine release version of v17.06. The Dockerfile&amp;rsquo;s &lt;code&gt;FROM&lt;/code&gt; instruction like below:&lt;/p&gt;

&lt;h4 id=&#34;from&#34;&gt;FROM&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;FROM &amp;lt;image&amp;gt; [AS &amp;lt;name&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM &amp;lt;image&amp;gt;[:&amp;lt;tag&amp;gt;] [AS &amp;lt;name&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM &amp;lt;image&amp;gt;[@&amp;lt;digest&amp;gt;] [AS &amp;lt;name&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Optionally a name can be given to a new build stage by adding &lt;code&gt;AS&lt;/code&gt; name to the &lt;code&gt;FROM&lt;/code&gt; instruction. The name can be used in subsequent &lt;code&gt;FROM&lt;/code&gt; and &lt;code&gt;COPY --from=&amp;lt;name|index&amp;gt;&lt;/code&gt; instructions to refer to the image built in this stage.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Find Docker-ce official document &lt;a href=&#34;https://docs.docker.com/v17.06/engine/reference/builder/#from&#34; title=&#34;Docker official Document&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;You can use this patch to build docker image if  docker-ce that version &amp;gt;=v17.06 is installed:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;docker version
Client:
 Version:      18.03.1-ce
 API version:  1.37
 Go version:   go1.9.5
 Git commit:   9ee9f40
 Built:        Thu Apr 26 07:20:16 2018
 OS/Arch:      linux/amd64
 Experimental: false
 Orchestrator: swarm

Server:
 Engine:
  Version:      18.03.1-ce
  API version:  1.37 (minimum version 1.12)
  Go version:   go1.9.5
  Git commit:   9ee9f40
  Built:        Thu Apr 26 07:23:58 2018
  OS/Arch:      linux/amd64
  Experimental: false
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Build docker image&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; cd $GOPATH/src/github.com/gogs/gogs
&amp;gt; docker build -t &amp;lt;your/image-tag&amp;gt; -f Dockerfile.docker-ce .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dockerfile.docker-ce&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM golang:1.10.3-alpine AS binarybuilder
# Install build deps
RUN apk --no-cache --no-progress add --virtual build-deps build-base git linux-pam-dev
WORKDIR /go/src/github.com/gogs/gogs
COPY . .
RUN make build TAGS=&amp;quot;sqlite cert pam&amp;quot;

FROM alpine:3.7
# Install system utils &amp;amp; Gogs runtime dependencies
ADD https://github.com/tianon/gosu/releases/download/1.10/gosu-amd64 /usr/sbin/gosu
RUN chmod +x /usr/sbin/gosu \
  &amp;amp;&amp;amp; echo http://dl-2.alpinelinux.org/alpine/edge/community/ &amp;gt;&amp;gt; /etc/apk/repositories \
  &amp;amp;&amp;amp; apk --no-cache --no-progress add \
    bash \
    ca-certificates \
    curl \
    git \
    linux-pam \
    openssh \
    s6 \
    shadow \
    socat \
    tzdata

ENV GOGS_CUSTOM /data/gogs

# Configure LibC Name Service
COPY docker/nsswitch.conf /etc/nsswitch.conf

WORKDIR /app/gogs
COPY docker ./docker
COPY templates ./templates
COPY public ./public
COPY --from=binarybuilder /go/src/github.com/gogs/gogs/gogs .

RUN ./docker/finalize-docker-ce.sh

# Configure Docker Container
VOLUME [&amp;quot;/data&amp;quot;]
EXPOSE 22 3000
ENTRYPOINT [&amp;quot;/app/gogs/docker/start.sh&amp;quot;]
CMD [&amp;quot;/bin/s6-svscan&amp;quot;, &amp;quot;/app/gogs/docker/s6/&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/gogs/gogs/pull/5322&#34; title=&#34;Gogs PR-5322&#34;&gt;Note a PR-5322 for Gogs.&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gogs: PR-5262</title>
      <link>http://alimy.me/post/dev_201806040842/</link>
      <pubDate>Mon, 04 Jun 2018 08:42:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201806040842/</guid>
      <description>&lt;h3 id=&#34;fix-make-build-failure-when-enviroment-of-gopath-have-multiple-items&#34;&gt;Fix make build failure when enviroment of &lt;code&gt;GOPATH&lt;/code&gt; have multiple items&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;[alimy@rover gogs]$ pwd
/home/alimy/art/arg/src/github.com/gogs/gogs
[alimy@rover gogs]$ echo $GOPATH
/home/alimy/art/ago:/home/alimy/art/arg
[alimy@rover gogs]$ make
go install &amp;quot;-v&amp;quot; -ldflags &#39;-X &amp;quot;github.com/gogs/gogs/pkg/setting.BuildTime=2018-06-04 06:17:19 UTC&amp;quot; -X &amp;quot;github.com/gogs/gogs/pkg/setting.BuildGitHash=c08aab90ec696b7fcc56b8da0a468e74d266b89e&amp;quot;&#39; -tags &#39;&amp;quot;&amp;quot;&#39;
cp &#39;/home/alimy/art/ago:/home/alimy/art/arg/bin/gogs&#39; .
cp: cannot stat &#39;/home/alimy/art/ago:/home/alimy/art/arg/bin/gogs&#39;: No such file or directory
Makefile:36: recipe for target &#39;build&#39; failed
make: *** [build] Error 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this scene &lt;code&gt;GOPATH&lt;/code&gt; have two item (/home/alimy/art/ago and /home/alimy/art/arg) and gogs source is not in first &lt;code&gt;GOPATH&lt;/code&gt; items, when excecute &lt;code&gt;go install ...&lt;/code&gt; will install to path that contain the source of gogs&amp;rsquo;s &lt;code&gt;GOPATH&lt;/code&gt; items. when cp gogs file back will occur error like above.
this patch fixed this problem.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[alimy@rover gogs]$ echo $GOPATH
/home/alimy/art/ago:/home/alimy/art/arg
[alimy@rover gogs]$ pwd
/home/alimy/art/arg/src/github.com/gogs/gogs
[alimy@rover gogs]$ echo ${PWD%%src*}
/home/alimy/art/arg/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Also when have multiple item in &lt;code&gt;GOPATH&lt;/code&gt; env you should do this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export GOPATH=$HOME/art/ago:$HOME/art/arg
export PATH=$GOROOT/bin:${GOPATH//://bin:}/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Gogs&amp;rsquo;s Makefile:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LDFLAGS += -X &amp;quot;github.com/gogs/gogs/pkg/setting.BuildTime=$(shell date -u &#39;+%Y-%m-%d %I:%M:%S %Z&#39;)&amp;quot;
LDFLAGS += -X &amp;quot;github.com/gogs/gogs/pkg/setting.BuildGitHash=$(shell git rev-parse HEAD)&amp;quot;

DATA_FILES := $(shell find conf | sed &#39;s/ /\\ /g&#39;)
LESS_FILES := $(wildcard public/less/gogs.less public/less/_*.less)
GENERATED  := pkg/bindata/bindata.go public/css/gogs.css

OS := $(shell uname)

TAGS = &amp;quot;&amp;quot;
BUILD_FLAGS = &amp;quot;-v&amp;quot;

RELEASE_ROOT = &amp;quot;release&amp;quot;
RELEASE_GOGS = &amp;quot;release/gogs&amp;quot;
NOW = $(shell date -u &#39;+%Y%m%d%I%M%S&#39;)
GOVET = go tool vet -composites=false -methods=false -structtags=false
GOPATH = $(shell echo $${PWD%%src*})

.PHONY: build pack release bindata clean

.IGNORE: public/css/gogs.css

all: build

check: test

dist: release

web: build
	./gogs web

govet:
	$(GOVET) gogs.go
	$(GOVET) models pkg routes

build: $(GENERATED)
	go install $(BUILD_FLAGS) -ldflags &#39;$(LDFLAGS)&#39; -tags &#39;$(TAGS)&#39;
	cp &#39;$(GOPATH)/bin/gogs&#39; .

build-dev: $(GENERATED) govet
	go install $(BUILD_FLAGS) -tags &#39;$(TAGS)&#39;
	cp &#39;$(GOPATH)/bin/gogs&#39; .

build-dev-race: $(GENERATED) govet
	go install $(BUILD_FLAGS) -race -tags &#39;$(TAGS)&#39;
	cp &#39;$(GOPATH)/bin/gogs&#39; .

pack:
	rm -rf $(RELEASE_GOGS)
	mkdir -p $(RELEASE_GOGS)
	cp -r gogs LICENSE README.md README_ZH.md templates public scripts $(RELEASE_GOGS)
	rm -rf $(RELEASE_GOGS)/public/config.codekit $(RELEASE_GOGS)/public/less
	cd $(RELEASE_ROOT) &amp;amp;&amp;amp; zip -r gogs.$(NOW).zip &amp;quot;gogs&amp;quot;

release: build pack

bindata: pkg/bindata/bindata.go

pkg/bindata/bindata.go: $(DATA_FILES)
	go-bindata -o=$@ -ignore=&amp;quot;\\.DS_Store|README.md|TRANSLATORS|auth.d&amp;quot; -pkg=bindata conf/...

less: public/css/gogs.css

public/css/gogs.css: $(LESS_FILES)
	@type lessc &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;&amp;amp; lessc $&amp;lt; &amp;gt;$@ || echo &amp;quot;lessc command not found, skipped.&amp;quot;

clean:
	go clean -i ./...

clean-mac: clean
	find . -name &amp;quot;.DS_Store&amp;quot; -print0 | xargs -0 rm

test:
	go test -cover -race ./...

fixme:
	grep -rnw &amp;quot;FIXME&amp;quot; cmd routers models pkg

todo:
	grep -rnw &amp;quot;TODO&amp;quot; cmd routers models pkg

# Legacy code should be remove by the time of release
legacy:
	grep -rnw &amp;quot;LEGACY&amp;quot; cmd routes models pkg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/gogs/gogs/pull/5262&#34; title=&#34;Gogs PR-5262&#34;&gt;Note a PR-5322 for Gogs.&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>收藏: 技术相关网站</title>
      <link>http://alimy.me/post/info_201805210818/</link>
      <pubDate>Mon, 21 May 2018 08:19:00 CST</pubDate>
      
      <guid>http://alimy.me/post/info_201805210818/</guid>
      <description>&lt;h3 id=&#34;kubernetes-https-kubernetes-io-kubernetes官网&#34;&gt;&lt;a href=&#34;https://kubernetes.io/&#34; title=&#34;Kubernetes官网&#34;&gt;Kubernetes&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/cn/docs/&#34; title=&#34;官方中文文档&#34;&gt;官方中文文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.feisky.xyz/zh/&#34; title=&#34;feisky版 Kubernetes指南&#34;&gt;Kubernetes指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/&#34; title=&#34;Jimmy版 Kubernetes指南&#34;&gt;Kubernetes指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://feisky.gitbooks.io/sdn/&#34; title=&#34;SDN指南&#34;&gt;SDN指南&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>NewSQL: 分布式数据库TiDB、CockroachDB</title>
      <link>http://alimy.me/post/dev_201805021940/</link>
      <pubDate>Wed, 02 May 2018 19:40:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201805021940/</guid>
      <description>&lt;h3 id=&#34;tidb-https-pingcap-com-pingcap官网&#34;&gt;&lt;a href=&#34;https://pingcap.com/&#34; title=&#34;PingCap官网&#34;&gt;TiDB&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;TiDB 开源分布式 NewSQL 关系型数据库
TiDB 是新一代开源分布式 NewSQL 数据库，模型受 Google Spanner / F1 论文的启发，实现了自动的水平伸缩，强一致性的分布式事务，基于 Raft 算法的多副本复制等重要 NewSQL 特性。TiDB 结合了 RDBMS 和 NoSQL 的优点，部署简单，在线弹性扩容和异步表结构变更不影响业务， 真正的异地多活及自动故障恢复保障数据安全，同时兼容 &lt;a href=&#34;https://mariadb.com/kb/en/library/documentation/&#34; title=&#34;MariaDB Documentation&#34;&gt;MySQL&lt;/a&gt; 协议，使迁移使用成本降到极低。&lt;/p&gt;

&lt;h3 id=&#34;cockroachdb-https-www-cockroachlabs-com-cockroach-labs-蟑螂db-小强db&#34;&gt;&lt;a href=&#34;https://www.cockroachlabs.com/&#34; title=&#34;Cockroach LABS&#34;&gt;CockroachDB&lt;/a&gt; (蟑螂DB/小强DB)&lt;/h3&gt;

&lt;p&gt;CockroachDB（中文名蟑螂DB，所以又可以称为小强DB），是构建于事务处理及强一致性KV存储上的分布式SQL数据库，支持水平扩展、自动容错处理、强一致性事务，并且提供SQL接口用于数据处理，是Google Spanner/F1的开源实现。
   CockroachDB适用于应用对数据要求精确、可靠、完全正确的场景，支持自动复制、均匀分布、基于极小配置的数据恢复，可用于分布式的、可复制的联机事务处理（OLTP），多数据中心的部署，私有云的基础构建，它不适用于读少写多的场景，可以用内存数据库来代替，也不适用于复杂的join查询，重量级的数据分析及联机分析处理（OLAP）。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;CockroachDB is a distributed SQL database built on a transactional and strongly-consistent key-value store. It scales horizontally; survives disk, machine, rack, and even datacenter failures with minimal latency disruption and no manual intervention; supports strongly-consistent ACID transactions; and provides a familiar SQL API for structuring, manipulating, and querying data.SQL queries reach CockroachDB&amp;rsquo;s cluster through the &lt;a href=&#34;https://www.postgresql.org/docs/10/static/index.html&#34; title=&#34;PostgreSQL 10.3 Documentation&#34;&gt;PostgreSQL&lt;/a&gt; wire protocol.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Logus:另一种简单、优雅、高效打Log的方式</title>
      <link>http://alimy.me/post/dev_201804192316/</link>
      <pubDate>Thu, 19 Apr 2018 23:16:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201804192316/</guid>
      <description>&lt;h3 id=&#34;起源&#34;&gt;起源：&lt;/h3&gt;

&lt;p&gt;最近项目中有使用Uber的&lt;a href=&#34;https://github.com/uber-go/zap&#34; title=&#34;zap in GitHub&#34;&gt;zap&lt;/a&gt;（Go语言生态中一种高效打印Log的实用库，久经考验）打印log，用的顺手，于是借鉴其中的设计思想，在Android环境下封装Log类提供相似功能。&lt;/p&gt;

&lt;h3 id=&#34;设计思想&#34;&gt;设计思想：&lt;/h3&gt;

&lt;p&gt;分离消息与数据域，避免字符串拼接和效率低的字符串格式化&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;把log信息分两段：消息和数据域；消息是必须的， 数据域是个数可变的键-值对&lt;/li&gt;
&lt;li&gt;消息仅仅是String，不带任何格式化或字符串拼接&lt;/li&gt;
&lt;li&gt;数据域是以key-value的形式成对作为参数传给打印函数，忽略最后一个不成对参数&lt;/li&gt;
&lt;li&gt;内部实现是使用StringBuilder组合最终要打印的信息，避免过多的字符串拼接导致log打印频繁时给gc过多压力&lt;/li&gt;
&lt;li&gt;StackTrace信息是可以设置打印或不打印&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;用例&#34;&gt;用例：&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;// file: MainActivity.java
@Override
protected void onResume() {
    super.onResume();
    Logus.d(&amp;quot;just a message&amp;quot;);
    Logus.e(&amp;quot;a field message&amp;quot;, &amp;quot;a&amp;quot;, 1);
    Logus.w(&amp;quot;3 fields but see 2&amp;quot;, &amp;quot;a&amp;quot;, 1, &amp;quot;b&amp;quot;, true, &amp;quot;c&amp;quot;);
    Logus.V(&amp;quot;Main&amp;quot;, &amp;quot;with prefix just a message&amp;quot;);
    Logus.E(&amp;quot;Main&amp;quot;, &amp;quot;with prefix 2 fields&amp;quot;, &amp;quot;a&amp;quot;, 10, &amp;quot;b&amp;quot;, false);
    Logus.E(&amp;quot;Main&amp;quot;, &amp;quot;with prefix 3 fields but log 2&amp;quot;, &amp;quot;a&amp;quot;, 10, &amp;quot;b&amp;quot;, true, &amp;quot;c&amp;quot;);
    Logus.setStackTrace(false);
    Logus.E(&amp;quot;Main&amp;quot;, &amp;quot;no stack trace with prefix&amp;quot;);
}

// 输出：
04-19 22:12:56.209 3256-3256/net.gility.note  D/Logus: MainActivity.java(425)#onResume &amp;gt; just a message
04-19 22:12:56.210 3256-3256/net.gility.note  E/Logus: MainActivity.java(426)#onResume &amp;gt; a field message { a=1; }
04-19 22:12:56.210 3256-3256/net.gility.note  W/Logus: MainActivity.java(427)#onResume &amp;gt; 3 fields but see 2 { a=1; b=true; }
04-19 22:12:56.211 3256-3256/net.gility.note  V/Logus: MainActivity.java(428)#onResume Main&amp;gt; with prefix just a message
04-19 22:12:56.212 3256-3256/net.gility.note  E/Logus: MainActivity.java(429)#onResume Main&amp;gt; with prefix 2 fields { a=10; b=false; }
04-19 22:12:56.213 3256-3256/net.gility.note  E/Logus: MainActivity.java(430)#onResume Main&amp;gt; with prefix 3 fields but log 2 { a=10; b=true; }
04-19 22:12:56.213 3256-3256/net.gility.note  D/Logus: &amp;gt; no stack trace no prefix
04-19 22:12:56.213 3256-3256/net.gility.note  E/Logus: Main&amp;gt; no stack trace with prefix
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;具体实现&#34;&gt;具体实现：&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;public final class Logus {
    // 数据域长度调整掩码,用于计算数据域长度；aInt &amp;amp; FIXED_LENGTH_MASK 相当于 aInt % 2 == 0 ? aInt : aInt - 1;
    private static final int FIXED_LENGTH_MASK = ~1;

    private static String sPreTag = &amp;quot;Logus&amp;quot;;        // 预设TAG
    private static String sPrePrefix = &amp;quot;&amp;quot;;          // 预设消息前缀
    private static boolean sIsStackTrace = true;    // 是否打印StackTrace Info

    /**
     * 设置TAG
     *
     * @param tag
     */
    public static void setTag(final String tag) {
        if (!TextUtils.isEmpty(tag)) {
            sPreTag = tag;
        }
    }

    /**
     * 设置消息前缀
     *
     * @param prefix
     */
    public static void setPrefix(final String prefix) {
        if (!TextUtils.isEmpty(prefix)) {
            sPrePrefix = prefix;
        } else {
            sPrePrefix = &amp;quot;&amp;quot;;
        }
    }

    /**
     * 设置是否打印StackTrace信息 （显示文件名(行数)#函数名:）
     *
     * @param isStackTrace true/false
     */
    public static void setStackTrace(boolean isStackTrace) {
        sIsStackTrace = isStackTrace;
    }

    /**
     * Verbose level log
     *
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void v(final String message, Object... fields) {
        printMsg(Log.VERBOSE, sPrePrefix, message, fields);
    }

    /**
     * Debug level log print
     *
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void d(final String message, Object... fields) {
        printMsg(Log.DEBUG, sPrePrefix, message, fields);
    }

    /**
     * Info level log print
     *
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void i(final String message, Object... fields) {
        printMsg(Log.INFO, sPrePrefix, message, fields);
    }

    /**
     * Warning level log print
     *
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void w(final String message, Object... fields) {
        printMsg(Log.WARN, sPrePrefix, message, fields);
    }

    /**
     * Error level log print
     *
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void e(final String message, Object... fields) {
        printMsg(Log.ERROR, sPrePrefix, message, fields);
    }

    /**
     * Verbose level log
     *
     * @param prefix  消息前缀
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void V(final String prefix, final String message, Object... fields) {
        printMsg(Log.VERBOSE, prefix, message, fields);
    }

    /**
     * Debug level log print
     *
     * @param prefix  消息前缀
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void D(final String prefix, final String message, Object... fields) {
        printMsg(Log.DEBUG, prefix, message, fields);
    }

    /**
     * Info level log print
     *
     * @param prefix  消息前缀
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void I(final String prefix, final String message, Object... fields) {
        printMsg(Log.INFO, prefix, message, fields);
    }

    /**
     * Warning level log print
     *
     * @param prefix  消息前缀
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void W(final String prefix, final String message, Object... fields) {
        printMsg(Log.WARN, prefix, message, fields);
    }

    /**
     * Error level log print
     *
     * @param prefix  消息前缀
     * @param message 消息
     * @param fields  数据域，键-值连续的数据对，必须确保fields的长度为偶数，否则最后一个数据将不会打印
     */
    public static void E(final String prefix, final String message, Object... fields) {
        printMsg(Log.ERROR, prefix, message, fields);
    }

    /**
     * 打印log
     *
     * @param level   log级别
     * @param prefix  前缀
     * @param message 消息体（必须的）
     * @param fields  数据域
     */
    private static void printMsg(final int level, final String prefix, final String message, Object... fields) {
        StringBuilder sb = new StringBuilder();
        // 添加栈信息（文件及函数信息）
        if (sIsStackTrace) {
            StackTraceElement[] elements = Thread.currentThread().getStackTrace();
            if (elements != null &amp;amp;&amp;amp; elements.length &amp;gt; 4) {
                sb.append(elements[4].getFileName());
                sb.append(&amp;quot;(&amp;quot;);
                sb.append(elements[4].getLineNumber());
                sb.append(&amp;quot;)#&amp;quot;);
                sb.append(elements[4].getMethodName());
                sb.append(&amp;quot; &amp;quot;);
            }
        }
        sb.append(prefix);
        sb.append(&amp;quot;&amp;gt; &amp;quot;);
        sb.append(message);
        if (fields.length &amp;gt; 1) {
            sb.append(&amp;quot; { &amp;quot;);
            for (int i = 0, j = fields.length &amp;amp; FIXED_LENGTH_MASK; i &amp;lt; j; ) {
                sb.append(String.valueOf(fields[i++]));
                sb.append(&amp;quot;=&amp;quot;);
                sb.append(String.valueOf(fields[i++]));
                sb.append(&amp;quot;; &amp;quot;);
            }
            sb.append(&amp;quot;}&amp;quot;);
        }
        switch (level) {
            case Log.VERBOSE:
                Log.v(sPreTag, sb.toString());
                break;
            case Log.DEBUG:
                Log.d(sPreTag, sb.toString());
                break;
            case Log.INFO:
                Log.i(sPreTag, sb.toString());
                break;
            case Log.WARN:
                Log.w(sPreTag, sb.toString());
                break;
            case Log.ERROR:
                Log.e(sPreTag, sb.toString());
                break;
            default:
                break;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>rsync: 基本命令和用法</title>
      <link>http://alimy.me/post/dev_201803241218/</link>
      <pubDate>Sat, 24 Mar 2018 12:18:00 CST</pubDate>
      
      <guid>http://alimy.me/post/dev_201803241218/</guid>
      <description>&lt;h3 id=&#34;1-说在前面的话&#34;&gt;1 说在前面的话&lt;/h3&gt;

&lt;p&gt;rsync官方网站: &lt;a href=&#34;https://www.samba.org/ftp/rsync/rsync.html,&#34; title=&#34;rsync官方网站&#34;&gt;https://www.samba.org/ftp/rsync/rsync.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;rsync是可以实现增量备份的工具。配合任务计划，rsync能实现定时或间隔同步，配合inotify或sersync，可以实现触发式的实时同步。&lt;/p&gt;

&lt;p&gt;rsync可以实现scp的远程拷贝(rsync不支持远程到远程的拷贝，但scp支持)、cp的本地拷贝、rm删除和&amp;rdquo;ls -l&amp;rdquo;显示文件列表等功能。但需要注意的是，rsync的最终目的或者说其原始目的是实现两端主机的文件同步，因此实现的scp/cp/rm等功能仅仅只是同步的辅助手段，且rsync实现这些功能的方式和这些命令是不一样的。事实上，rsync有一套自己的算法，其算法原理以及rsync对算法实现的机制可能比想象中要复杂一些。平时使用rsync实现简单的备份、同步等功能足以，没有多大必要去深究这些原理性的内容。但是想要看懂rsync命令的man文档、使用&amp;rdquo;-vvvv&amp;rdquo;分析rsync执行过程，以及实现rsync更强大更完整的功能，没有这些理论知识的支持是绝对不可能实现的。本篇文章将简单介绍rsync的使用方法和它常用的功能。在本篇文章之后的下几篇文章中，将介绍inotify+rsync和sersync，再之后将详细解释rsync相关的原理，其中包括官方技术报告的翻译(即算法原理)、rsync同步的整个过程(也是官方推荐文章的翻译)，然后专门使用一篇文章通过示例来详细解释rsync算法原理，最后给出rsync的man文档翻译。希望各位朋友能藉此深入rsync。&lt;/p&gt;

&lt;p&gt;回归正题，以下是rsync相关基础内容。&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-rsync同步基本说明&#34;&gt;2 rsync同步基本说明&lt;/h3&gt;

&lt;p&gt;rsync的目的是实现本地主机和远程主机上的文件同步(包括本地推到远程，远程拉到本地两种同步方式)，也可以实现本地不同路径下文件的同步，但不能实现远程路径1到远程路径2之间的同步(scp可以实现)。&lt;/p&gt;

&lt;p&gt;不考虑rsync的实现细节，就文件同步而言，涉及了源文件和目标文件的概念，还涉及了以哪边文件为同步基准。例如，想让目标主机上的文件和本地文件保持同步，则是以本地文件为同步基准，将本地文件作为源文件推送到目标主机上。反之，如果想让本地主机上的文件和目标主机上的文件保持同步，则目标主机上的文件为同步基准，实现方式是将目标主机上的文件作为源文件拉取到本地。当然，要保持本地的两个文件相互同步，rsync也一样能实现，这就像Linux中cp命令一样，以本地某文件作为源，另一文件作为目标文件，但请注意，虽然rsync和cp能达到相同的目的，但它们的实现方式是不一样的。&lt;/p&gt;

&lt;p&gt;既然是文件同步，在同步过程中必然会涉及到源和目标两文件之间版本控制的问题，例如是否要删除源主机上没有但目标上多出来的文件，目标文件比源文件更新(newer than source)时是否仍要保持同步，遇到软链接时是拷贝软链接本身还是拷贝软链接所指向的文件，目标文件已存在时是否要先对其做个备份等等。&lt;/p&gt;

&lt;p&gt;rsync同步过程中由两部分模式组成：决定哪些文件需要同步的检查模式以及文件同步时的同步模式。&lt;/p&gt;

&lt;p&gt;(1).检查模式是指按照指定规则来检查哪些文件需要被同步，例如哪些文件是明确被排除不传输的。默认情况下，rsync使用&amp;rdquo;quick check&amp;rdquo;算法快速检查源文件和目标文件的大小、mtime(修改时间)是否一致，如果不一致则需要传输。当然，也可以通过在rsync命令行中指定某些选项来改变quick check的检查模式，比如&amp;rdquo;&amp;ndash;size-only&amp;rdquo;选项表示&amp;rdquo;quick check&amp;rdquo;将仅检查文件大小不同的文件作为待传输文件。rsync支持非常多的选项，其中检查模式的自定义性是非常有弹性的。&lt;/p&gt;

&lt;p&gt;(2).同步模式是指在文件确定要被同步后，在同步过程发生之前要做哪些额外工作。例如上文所说的是否要先删除源主机上没有但目标主机上有的文件，是否要先备份已存在的目标文件，是否要追踪链接文件等额外操作。rsync也提供非常多的选项使得同步模式变得更具弹性。&lt;/p&gt;

&lt;p&gt;相对来说，为rsync手动指定同步模式的选项更常见一些，只有在有特殊需求时才指定检查模式，因为大多数检查模式选项都可能会影响rsync的性能。&lt;/p&gt;

&lt;h3 id=&#34;3-rsync三种工作方式&#34;&gt;3 rsync三种工作方式&lt;/h3&gt;

&lt;p&gt;以下是rsync的语法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
Local:  rsync [OPTION...] SRC... [DEST]

Access via remote shell:
  Pull: rsync [OPTION...] [USER@]HOST:SRC... [DEST]
  Push: rsync [OPTION...] SRC... [USER@]HOST:DEST

Access via rsync daemon:
  Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST]
        rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST]
  Push: rsync [OPTION...] SRC... [USER@]HOST::DEST
        rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由此语法可知，rsync有三种工作方式：&lt;/p&gt;

&lt;p&gt;(1).本地文件系统上实现同步。命令行语法格式为上述&amp;rdquo;Local&amp;rdquo;段的格式。&lt;/p&gt;

&lt;p&gt;(2).本地主机使用远程shell和远程主机通信。命令行语法格式为上述&amp;rdquo;Access via remote shell&amp;rdquo;段的格式。&lt;/p&gt;

&lt;p&gt;(3).本地主机通过网络套接字连接远程主机上的rsync daemon。命令行语法格式为上述&amp;rdquo;Access via rsync daemon&amp;rdquo;段的格式。&lt;/p&gt;

&lt;p&gt;前两者的本质是通过管道通信，即使是远程shell。而方式(3)则是让远程主机上运行rsync服务，使其监听在一个端口上，等待客户端的连接。&lt;/p&gt;

&lt;p&gt;但是，通过远程shell也能临时启动一个rsync daemon，这不同于方式(3)，它不要求远程主机上事先启动rsync服务，而是临时派生出rsync daemon，它是单用途的一次性daemon，仅用于临时读取daemon的配置文件，当此次rsync同步完成，远程shell启动的rsync daemon进程也会自动消逝。此通信方式的命令行语法格式同&amp;rdquo;Access via rsync daemon&amp;rdquo;，但要求options部分必须明确指定&amp;rdquo;&amp;ndash;rsh&amp;rdquo;选项或其短选项&amp;rdquo;-e&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;以下是对rsync语法的简单说明，由于rsync支持一百多个选项，所以此处只介绍几个常用选项。完整的选项说明以及rsync的使用方法见我翻译的&amp;rdquo;man rsync&amp;rdquo;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Local:  rsync [OPTION...] SRC... [DEST]

Access via remote shell:
  Pull: rsync [OPTION...] [USER@]HOST:SRC... [DEST]
  Push: rsync [OPTION...] SRC... [USER@]HOST:DEST

Access via rsync daemon:
  Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST]
        rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST]
  Push: rsync [OPTION...] SRC... [USER@]HOST::DEST
        rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，第一个路径参数一定是源文件路径，即作为同步基准的一方，可以同时指定多个源文件路径。最后一个路径参数则是目标文件路径，也就是待同步方。路径的格式可以是本地路径，也可以是使用user@host:path或user@host::path的远程路径，如果主机和path路径之间使用单个冒号隔开，表示使用的是远程shell通信方式，而使用双冒号隔开的则表示的是连接rsync daemon。另外，连接rsync daemon时，还提供了URL格式的路径表述方式rsync://user@host/path。&lt;/p&gt;

&lt;p&gt;如果仅有一个SRC或DEST参数，则将以类似于&amp;rdquo;ls -l&amp;rdquo;的方式列出源文件列表(只有一个路径参数，总会认为是源文件)，而不是复制文件。&lt;/p&gt;

&lt;p&gt;如果对rsync不熟悉，可暂先只了解本地以及远程shell格式的user@host:path路径格式。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync /etc/fstab /tmp                # 在本地同步
[root@xuexi ~]# rsync -r /etc 172.16.10.5:/tmp       # 将本地/etc目录拷贝到远程主机的/tmp下，以保证远程/tmp目录和本地/etc保持同步
[root@xuexi ~]# rsync -r 172.16.10.5:/etc /tmp       # 将远程主机的/etc目录拷贝到本地/tmp下，以保证本地/tmp目录和远程/etc保持同步
[root@xuexi ~]# rsync /etc/                          # 列出本地/etc/目录下的文件列表
[root@xuexi ~]# rsync 172.16.10.5:/tmp/              # 列出远程主机上/tmp/目录下的文件列表
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外，使用rsync一定要注意的一点是，源路径如果是一个目录的话，带上尾随斜线和不带尾随斜线是不一样的，不带尾随斜线表示的是整个目录包括目录本身，带上尾随斜线表示的是目录中的文件，不包括目录本身。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync /etc /tmp
[root@xuexi ~]# rsync /etc/ /tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;第一个命令会在/tmp目录下创建etc目录，而第二个命令不会在/tmp目录下创建etc目录，源路径/etc/中的所有文件都直接放在/tmp目录下。&lt;/p&gt;

&lt;h3 id=&#34;4-选项说明和示例&#34;&gt;4 选项说明和示例&lt;/h3&gt;

&lt;p&gt;接下来是rsync的选项说明。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-v：显示rsync过程中详细信息。可以使用&amp;quot;-vvvv&amp;quot;获取更详细信息。
-P：显示文件传输的进度信息。(实际上&amp;quot;-P&amp;quot;=&amp;quot;--partial --progress&amp;quot;，其中的&amp;quot;--progress&amp;quot;才是显示进度信息的)。
-n --dry-run  ：仅测试传输，而不实际传输。常和&amp;quot;-vvvv&amp;quot;配合使用来查看rsync是如何工作的。
-a --archive  ：归档模式，表示递归传输并保持文件属性。等同于&amp;quot;-rtopgDl&amp;quot;。
-r --recursive：递归到目录中去。
-t --times：保持mtime属性。强烈建议任何时候都加上&amp;quot;-t&amp;quot;，否则目标文件mtime会设置为系统时间，导致下次更新
          ：检查出mtime不同从而导致增量传输无效。
-o --owner：保持owner属性(属主)。
-g --group：保持group属性(属组)。
-p --perms：保持perms属性(权限，不包括特殊权限)。
-D        ：是&amp;quot;--device --specials&amp;quot;选项的组合，即也拷贝设备文件和特殊文件。
-l --links：如果文件是软链接文件，则拷贝软链接本身而非软链接所指向的对象。
-z        ：传输时进行压缩提高效率。
-R --relative：使用相对路径。意味着将命令行中指定的全路径而非路径最尾部的文件名发送给服务端，包括它们的属性。用法见下文示例。
--size-only ：默认算法是检查文件大小和mtime不同的文件，使用此选项将只检查文件大小。
-u --update ：仅在源mtime比目标已存在文件的mtime新时才拷贝。注意，该选项是接收端判断的，不会影响删除行为。
-d --dirs   ：以不递归的方式拷贝目录本身。默认递归时，如果源为&amp;quot;dir1/file1&amp;quot;，则不会拷贝dir1目录，使用该选项将拷贝dir1但不拷贝file1。
--max-size  ：限制rsync传输的最大文件大小。可以使用单位后缀，还可以是一个小数值(例如：&amp;quot;--max-size=1.5m&amp;quot;)
--min-size  ：限制rsync传输的最小文件大小。这可以用于禁止传输小文件或那些垃圾文件。
--exclude   ：指定排除规则来排除不需要传输的文件。
--delete    ：以SRC为主，对DEST进行同步。多则删之，少则补之。注意&amp;quot;--delete&amp;quot;是在接收端执行的，所以它是在
            ：exclude/include规则生效之后才执行的。
-b --backup ：对目标上已存在的文件做一个备份，备份的文件名后默认使用&amp;quot;~&amp;quot;做后缀。
--backup-dir：指定备份文件的保存路径。不指定时默认和待备份文件保存在同一目录下。
-e          ：指定所要使用的远程shell程序，默认为ssh。
--port      ：连接daemon时使用的端口号，默认为873端口。
--password-file：daemon模式时的密码文件，可以从中读取密码实现非交互式。注意，这不是远程shell认证的密码，而是rsync模块认证的密码。
-W --whole-file：rsync将不再使用增量传输，而是全量传输。在网络带宽高于磁盘带宽时，该选项比增量传输更高效。
--existing  ：要求只更新目标端已存在的文件，目标端还不存在的文件不传输。注意，使用相对路径时如果上层目录不存在也不会传输。
--ignore-existing：要求只更新目标端不存在的文件。和&amp;quot;--existing&amp;quot;结合使用有特殊功能，见下文示例。
--remove-source-files：要求删除源端已经成功传输的文件。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;rsync的选项非常多，能够实现非常具有弹性的功能，以上选项仅仅只是很小一部分常用的选项，关于更完整更详细的选项说明，见我的rsync man手册翻译。&lt;/p&gt;

&lt;p&gt;虽然选项非常多，但最常用的选项组合是&amp;rdquo;avz&amp;rdquo;，即压缩和显示部分信息，并以归档模式传输。&lt;/p&gt;

&lt;h4 id=&#34;4-1-基础示例&#34;&gt;4.1 基础示例&lt;/h4&gt;

&lt;p&gt;以下是几个本地同步示例和通过远程shell实现的同步示例，示例中没有使用&amp;rdquo;-a&amp;rdquo;选项，目的是为了更清晰地说明各选项的作用。&lt;/p&gt;

&lt;p&gt;(1).将/etc/fstab拷贝到/tmp目录下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync /etc/fstab /tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(2).将/etc/cron.d目录拷贝到/tmp下。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -r /etc/cron.d /tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该命令会在目标主机上创建/tmp/cron.d目录，并将/etc/cron.d/中的文件放入到/tmp/cron.d/目录中，也就是说默认情况下，是不会在目录路径下创建上层目录/etc的。&lt;/p&gt;

&lt;p&gt;(3).将/etc/cron.d目录拷贝到/tmp下，但要求在/tmp下也生成etc子目录。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -R -r /etc/cron.d /tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中&amp;rdquo;-R&amp;rdquo;选项表示使用相对路径，此相对路径是以目标目录为根的。对于上面的示例，表示在目标上的/tmp下创建etc/cron.d目录，即/tmp/etc/cron.d，etc/cron.d的根&amp;rdquo;/&amp;ldquo;代表的就是目标/tmp。&lt;/p&gt;

&lt;p&gt;如果要拷贝的源路径较长，但只想在目标主机上保留一部分目录结构，例如要拷贝/var/log/anaconda/*到/tmp下，但只想在/tmp下保留从log开始的目录，如何操作？使用一个点代表相对路径的起始位置即可，也就是将长目录进行划分。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -R -r /var/./log/anaconda /tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样，从点开始的目录都是相对路径，其相对根目录为目标路径。所以对于上面的示例，将在目标上创建/tmp/log/anaconda/*。&lt;/p&gt;

&lt;p&gt;(4).对远程目录下已存在文件做一个备份。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -R -r --backup /var/./log/anaconda /tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样在目标目录下，已存在的文件就被做一个备份，备份文件默认使用&amp;rdquo;~&amp;ldquo;做后缀，可以使用&amp;rdquo;&amp;ndash;suffix&amp;rdquo;指定备份后缀。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi tmp]# ll log/anaconda/
total 3112
-rw------- 1 root root    6668 Jul 14 12:45 anaconda.log
-rw------- 1 root root    6668 Jul 14 11:44 anaconda.log~
-rw------- 1 root root    3826 Jul 14 12:45 ifcfg.log
-rw------- 1 root root    3826 Jul 14 11:44 ifcfg.log~
-rw------- 1 root root 1102699 Jul 14 12:45 journal.log
-rw------- 1 root root 1102699 Jul 14 11:44 journal.log~
-rw------- 1 root root       0 Jul 14 12:45 ks-script-1uLekR.log
-rw------- 1 root root       0 Jul 14 11:44 ks-script-1uLekR.log~
-rw------- 1 root root       0 Jul 14 12:45 ks-script-iGpl4q.log
-rw------- 1 root root       0 Jul 14 11:44 ks-script-iGpl4q.log~
-rw------- 1 root root  160420 Jul 14 12:45 packaging.log
-rw------- 1 root root  160420 Jul 14 11:44 packaging.log~
-rw------- 1 root root   27906 Jul 14 12:45 program.log
-rw------- 1 root root   27906 Jul 14 11:44 program.log~
-rw------- 1 root root   78001 Jul 14 12:45 storage.log
-rw------- 1 root root   78001 Jul 14 11:44 storage.log~
-rw------- 1 root root  197961 Jul 14 12:45 syslog
-rw------- 1 root root  197961 Jul 14 11:44 syslog~
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以使用&amp;rdquo;&amp;ndash;backup-dir&amp;rdquo;指定备份文件保存路径，但要求保存路径必须存在。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# mkdir /tmp/log_back

[root@xuexi ~]# rsync -R -r --backup --backup-dir=/tmp/log_back /var/./log/anaconda /tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;指定备份路径后，默认将不会加备份后缀，除非使用&amp;rdquo;&amp;ndash;suffix&amp;rdquo;显式指定后缀，如&amp;rdquo;&amp;ndash;suffix=~&amp;ldquo;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi tmp]# tree /tmp/log_back/
/tmp/log_back/
└── log
    └── anaconda
        ├── anaconda.log
        ├── ifcfg.log
        ├── journal.log
        ├── ks-script-1uLekR.log
        ├── ks-script-iGpl4q.log
        ├── packaging.log
        ├── program.log
        ├── storage.log
        └── syslog
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(5).指定ssh连接参数，如端口、连接的用户、ssh选项等。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi tmp]# &amp;gt;~/.ssh/known_hosts   # 先清空host key以便下面的测试

[root@xuexi tmp]# rsync -e &amp;quot;ssh -p 22 -o StrictHostKeyChecking=no&amp;quot; /etc/fstab 172.16.10.5:/tmp
Warning: Permanently added &#39;172.16.10.5&#39; (RSA) to the list of known hosts.
root@172.16.10.5&#39;s password:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可见直接指定ssh参数是生效的。&lt;/p&gt;

&lt;p&gt;(6).&amp;ldquo;&amp;ndash;existing&amp;rdquo;和&amp;rdquo;&amp;ndash;ignore-existing&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&amp;rdquo;&amp;ndash;existing&amp;rdquo;是只更新目标端已存在的文件。&lt;/p&gt;

&lt;p&gt;目前/tmp/{a,b}目录中内容如下，bashrc在a目录中，crontab在b目录中，且a目录中多了一个c子目录。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# tree /tmp/{a,b}
/tmp/a
├── bashrc
├── c
│   └── find
├── fstab
├── profile
└── rc.local
/tmp/b
├── crontab
├── fstab
├── profile
└── rc.local

1 directory, 9 files
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用&amp;rdquo;&amp;ndash;existing&amp;rdquo;选项使得只更新目标端已存在的文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -r -v --existing /tmp/a/ /tmp/b           
sending incremental file list
fstab
profile
rc.local

sent 2972 bytes  received 70 bytes  6084.00 bytes/sec
total size is 204755  speedup is 67.31
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果只有3个目标上已存在的文件被更新了，由于目标上没有c目录，所以c目录中的文件也没有进行传输。&lt;/p&gt;

&lt;p&gt;而&amp;rdquo;&amp;ndash;ignore-existing&amp;rdquo;是更新目标端不存在的文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -r -v --ignore-existing /tmp/a/ /tmp/b
sending incremental file list
bashrc
c/
c/find

sent 202271 bytes  received 54 bytes  404650.00 bytes/sec
total size is 204755  speedup is 1.01
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(7).&amp;ldquo;&amp;ndash;remove-source-files&amp;rdquo;删除源端文件。&lt;/p&gt;

&lt;p&gt;使用该选项后，源端已经更新成功的文件都会被删除，源端所有未传输或未传输成功的文件都不会被移除。未传输成功的原因有多种，如exclude排除了，&amp;rdquo;quick check&amp;rdquo;未选项该文件，传输中断等等。&lt;/p&gt;

&lt;p&gt;总之，显示在&amp;rdquo;rsync -v&amp;rdquo;被传输列表中的文件都会被移除。如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -r -v --remove-source-files /tmp/a/anaconda /tmp/a/audit /tmp       
sending incremental file list
anaconda/anaconda.log
anaconda/ifcfg.log
anaconda/journal.log
anaconda/ks-script-1uLekR.log
anaconda/ks-script-iGpl4q.log
anaconda/packaging.log
anaconda/program.log
anaconda/storage.log
anaconda/syslog
audit/audit.log

sent 4806915 bytes  received 204 bytes  9614238.00 bytes/sec
total size is 4805676  speedup is 1.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上述显示出来的文件在源端全部被删除。&lt;/p&gt;

&lt;h4 id=&#34;4-2-exclude-排除规则&#34;&gt;4.2 &amp;ldquo;&amp;ndash;exclude&amp;rdquo;排除规则&lt;/h4&gt;

&lt;p&gt;使用&amp;rdquo;&amp;ndash;exclude&amp;rdquo;选项指定排除规则，排除那些不需要传输的文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi tmp]# rsync -r -v --exclude=&amp;quot;anaconda/*.log&amp;quot; /var/log/anaconda /var/log/audit /tmp
sending incremental file list
anaconda/
anaconda/syslog
audit/
audit/audit.log

sent 3365629 bytes  received 58 bytes  6731374.00 bytes/sec
total size is 3365016  speedup is 1.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上例中只排除了anaconda目录中的log文件，但是audit目录中的log文件是正常传输的。&lt;/p&gt;

&lt;p&gt;注意，一个&amp;rdquo;&amp;ndash;exclude&amp;rdquo;只能指定一条规则，要指定多条排除规则，需要使用多个&amp;rdquo;&amp;ndash;exclude&amp;rdquo;选项，或者将排除规则写入到文件中，然后使用&amp;rdquo;&amp;ndash;exclude-from&amp;rdquo;选项读取该规则文件。&lt;/p&gt;

&lt;p&gt;另外，除了&amp;rdquo;&amp;ndash;exclude&amp;rdquo;排除规则，还有&amp;rdquo;&amp;ndash;include&amp;rdquo;包含规则，顾名思义，它就是筛选出要进行传输的文件，所以include规则也称为传输规则。它的使用方法和&amp;rdquo;&amp;ndash;exclude&amp;rdquo;一样。如果一个文件即能匹配排除规则，又能匹配包含规则，则先匹配到的立即生效，生效后就不再进行任何匹配。&lt;/p&gt;

&lt;p&gt;最后，关于规则，最重要的一点是它的作用时间。当发送端敲出rsync命令后，rsync将立即扫描命令行中给定的文件和目录(扫描过程中还会按照目录进行排序，将同一个目录的文件放在相邻的位置)，这称为拷贝树(copy tree)，扫描完成后将待传输的文件或目录记录到文件列表中，然后将文件列表传输给接收端。而筛选规则的作用时刻是在扫描拷贝树时，所以会根据规则来匹配并决定文件是否记录到文件列表中(严格地说是会记录到文件列表中的，只不过排除的文件会被标记为hide隐藏起来)，只有记录到了文件列表中的文件或目录才是真正需要传输的内容。换句话说，筛选规则的生效时间在rsync整个同步过程中是非常靠前的，它会影响很多选项的操作对象，最典型的如&amp;rdquo;&amp;ndash;delete&amp;rdquo;。也许，你看完这一整篇文章都没感觉到这一点的重要性，但如果你阅读rsync的man文档或者学习rsync的原理，你一定会深有体会。&lt;/p&gt;

&lt;p&gt;实际上，排除规则和包含规则都只是&amp;rdquo;&amp;ndash;filter&amp;rdquo;筛选规则的两种特殊规则。&amp;rdquo;&amp;ndash;filter&amp;rdquo;比较复杂，它有自己的规则语法和匹配模式，由于篇幅有限，以及考虑到本文的难度定位，&amp;rdquo;&amp;ndash;filter&amp;rdquo;规则不便在此多做解释，仅简单说明下规则类，帮助理解下文的&amp;rdquo;&amp;ndash;delete&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;以下是rsync中的规则种类，不解之处请结合下文的&amp;rdquo;&amp;ndash;delete&amp;rdquo;分析：&lt;/p&gt;

&lt;p&gt;(1).exclude规则：即排除规则，只作用于发送端，被排除的文件不会进入文件列表(实际上是加上隐藏规则进行隐藏)。&lt;/p&gt;

&lt;p&gt;(2).include规则：即包含规则，也称为传输规则，只作用于发送端，被包含的文件将明确记录到文件列表中。&lt;/p&gt;

&lt;p&gt;(3).hide规则：即隐藏规则，只作用于发送端，隐藏后的文件对于接收端来说是看不见的，也就是说接收端会认为它不存在于源端。&lt;/p&gt;

&lt;p&gt;(4).show规则：即显示规则，只作用于发送端，是隐藏规则的反向规则。&lt;/p&gt;

&lt;p&gt;(5).protect规则：即保护规则，该规则只作用于接收端，被保护的文件不会被删除掉。&lt;/p&gt;

&lt;p&gt;(6).risk规则：即取消保护规则。是protect的反向规则。&lt;/p&gt;

&lt;p&gt;除此之外，还有一种规则是&amp;rdquo;clear规则&amp;rdquo;，作用是删除include/exclude规则列表。&lt;/p&gt;

&lt;h4 id=&#34;4-3-delete-解释&#34;&gt;4.3 &amp;ldquo;&amp;ndash;delete&amp;rdquo;解释&lt;/h4&gt;

&lt;p&gt;使用&amp;rdquo;&amp;ndash;delete&amp;rdquo;选项后，接收端的rsync会先删除目标目录下已经存在，但源端目录不存在的文件。也就是&amp;rdquo;多则删之，少则补之&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;例如，先实现一次同步，再向目标目录中拷贝一个新文件，这样目标目录中就比源目录多出一个文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -r /etc/cron.d /tmp/

[root@xuexi ~]# cp /etc/fstab /tmp/cron.d/

[root@xuexi ~]# ls /tmp/cron.d/
0hourly  fstab  raid-check  sysstat
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再使用&amp;rdquo;&amp;ndash;delete&amp;rdquo;选项，这时会将目标端多出的文件给删除掉，然后进行同步。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -r -v /etc/cron.d /tmp --delete
sending incremental file list
deleting cron.d/fstab
cron.d/0hourly
cron.d/raid-check
cron.d/sysstat

sent 704 bytes  received 70 bytes  1548.00 bytes/sec
total size is 471  speedup is 0.61
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样的行为实现了远程删除的功能，对于作用于本地的rsync，也就实现了rm的本地删除功能。而且，如果使用空目录作为源目录，则它的作用是清空目录上的整个目录。&lt;/p&gt;

&lt;p&gt;如果将&amp;rdquo;&amp;ndash;delete&amp;rdquo;选项和&amp;rdquo;&amp;ndash;exlcude&amp;rdquo;选项一起使用，则被排除的文件不会被删除。例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync -r /var/log/anaconda /var/log/audit /tmp  # 先进行一次同步以便测试

[root@xuexi ~]# cp /etc/fstab /tmp/anaconda/                    # 拷贝一个新文件到目标目录以便测试

[root@xuexi ~]# rsync -r -v --exclude=&amp;quot;anaconda/*.log&amp;quot; /var/log/anaconda /var/log/audit /tmp --delete
sending incremental file list
deleting anaconda/fstab
anaconda/syslog
audit/audit.log

sent 3406190 bytes  received 52 bytes  6812484.00 bytes/sec
total size is 3405579  speedup is 1.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果发现只删除了&amp;rdquo;anaconda/fstab&amp;rdquo;文件，被&amp;rdquo;&amp;ndash;exclude&amp;rdquo;规则匹配的anaconda/*.log文件都没有被删除。也就是网上所说的言论：exclude排除的文件不会被删除。&lt;/p&gt;

&lt;p&gt;结论是没错的，但我想很多人不知道为何会如此，也可能从来没想过为何会如此，所以我简单地做个说明。&lt;/p&gt;

&lt;p&gt;在发送端将文件列表发送给接收端后，接收端的generator(要是不知道，你认为是某个就好了)进程会扫描每个文件列表中的信息，然后对列表中的每个信息条目都计算数据块校验码，最后将数据库校验码发给发送端，发送端通过校验码来匹配哪些数据块是需要传输的，这样就实现了增量传输的功能——只传输改变的部分，不会传输整个文件。而delete删除的时间点是generator进程处理每个文件列表时、生成校验码之前进行的，先将目标上存在但源上不存在的多余文件删除，这样就无需为多余的文件生成校验码。&lt;/p&gt;

&lt;p&gt;所以，delete动作是比&amp;rdquo;&amp;ndash;exclude&amp;rdquo;规则更晚执行的，被&amp;rdquo;&amp;ndash;exlcude&amp;rdquo;规则排除的文件不会进入文件列表中，在执行了delete时会认为该文件不存在于源端，从而导致目标端将这些文件删除。但这是想当然的，尽管理论上确实是这样的，但是rsync为了防止众多误删除情况，提供了两种规则：保护规则(protect)和取消保护规则(risk)。默认情况下，&amp;rdquo;&amp;ndash;delete&amp;rdquo;和&amp;rdquo;&amp;ndash;exclude&amp;rdquo;一起使用时，虽然发送端的exclude规则将文件标记为隐藏，使得接收端认为这些被排除文件在源端不存在，但rsync会将这些隐藏文件标记为保护文件，使得它们不受delete行为的影响，这样delete就删除不了这些被排除的文件。如果还是想要强行删除被exclude排除的文件，可以使用&amp;rdquo;&amp;ndash;delete-excluded&amp;rdquo;选项强制取消保护，这样即使被排除的文件也会被删除。&lt;/p&gt;

&lt;p&gt;那么现在，是否理解了网上的言论&amp;rdquo;exclude排除的文件不会被删除&amp;rdquo;？&lt;/p&gt;

&lt;p&gt;除了&amp;rdquo;&amp;ndash;delete&amp;rdquo;，相关的选项还有&amp;rdquo;&amp;ndash;delete-before&amp;rdquo;、&amp;rdquo;&amp;ndash;delete-during&amp;rdquo;、&amp;rdquo;&amp;ndash;delete-delay&amp;rdquo;等，它们都隐含了&amp;rdquo;&amp;ndash;delete&amp;rdquo;选项，它们分别表示generator处理各个文件列表之前一次性全部删除待删除文件、处理文件列表时处理到哪个文件列表就删除该文件列表中的待删除文件，以及同步完所有数据后一次性删除所有待删除文件。&lt;/p&gt;

&lt;p&gt;举个例子，假如源端要传输3个目录a、b、c，在目标端a目录中有a1、a2、a3共3个文件需要被删除，b目录中有b1、b2、b3需要删除，同理c目录也一样c1、c2、c3需要被删除。&lt;/p&gt;

&lt;p&gt;如果是&amp;rdquo;&amp;ndash;delete-before&amp;rdquo;，则在目标端rsync刚启动时，就会把a1-a3、b1-b3、c1-c3一次性删除，然后才会处理文件列表中的a目录，处理完a后处理b，再是c。&lt;/p&gt;

&lt;p&gt;如果是&amp;rdquo;&amp;ndash;delete-during&amp;rdquo;，则在目标端rsync刚启动时，先处理文件列表中的a目录，处理a目录时发现此目录中有待删除文件a1-a3，顺手就删除它们，然后完成a目录的相关操作，再处理文件列表中的b目录，发现也有待删除文件b1-b3，顺手删除它们，同理c1-c3也如此。&lt;/p&gt;

&lt;p&gt;如果是&amp;rdquo;&amp;ndash;delete-delay&amp;rdquo;，则同步完文件列表中的a/b/c目录后，最后一次性删除a1-a3、b1-b3、c1-c3。&lt;/p&gt;

&lt;p&gt;其实&amp;rdquo;&amp;ndash;delete&amp;rdquo;选项大多数情况下默认采用的就是&amp;rdquo;&amp;ndash;delete-during&amp;rdquo;。&lt;/p&gt;

&lt;h3 id=&#34;5-rsync-daemon模式&#34;&gt;5 rsync daemon模式&lt;/h3&gt;

&lt;h4 id=&#34;5-1-简单介绍&#34;&gt;5.1 简单介绍&lt;/h4&gt;

&lt;p&gt;既然rsync通过远程shell就能实现两端主机上的文件同步，还要使用rsync的服务干啥？试想下，你有的机器上有一堆文件需要时不时地同步到众多机器上去，比如目录a、b、c是专门传输到web服务器上的，d/e、f、g/h是专门传输到ftp服务器上的，还要对这些目录中的某些文件进行排除，如果通过远程shell连接方式，无论是使用排除规则还是包含规则，甚至一条一条rsync命令地传输，这都没问题，但太过繁琐且每次都要输入同样的命令显得太死板。使用rsync daemon就可以解决这种死板问题。而且，rsync daemon是向外提供服务的，这样只要告诉了别人rsync的url路径，外人就能向ftp服务器一样获取文件列表并进行选择性地下载，所以，你所制定的列表，你的同事也可以获取到并使用。&lt;/p&gt;

&lt;p&gt;举个简单的例子，Linux内核官网www.kernel.org提供rsync的下载方式，官方给出的地址是rsync://rsync.kernel.org/pub，可以根据这个地址找出你想下载的内核版本。例如要找出linux-3.0.15版本的内核相关文件。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync --no-motd -r -v -f &amp;quot;+ */&amp;quot; -f &amp;quot;+ linux-3.0.15*&amp;quot; -f &amp;quot;- *&amp;quot; -m rsync://rsync.kernel.org/pub/
receiving file list ... done
drwxr-xr-x         124 2017/07/14 20:27:22 .
drwxr-xr-x         178 2014/11/12 05:50:10 linux
drwxr-xr-x        4096 2017/06/27 05:46:27 linux/kernel
drwxr-xr-x      237568 2017/07/05 20:49:33 linux/kernel/v3.x
-rw-r--r--    76803806 2012/01/04 03:00:31 linux/kernel/v3.x/linux-3.0.15.tar.bz2
-rw-r--r--    96726195 2012/01/04 03:00:31 linux/kernel/v3.x/linux-3.0.15.tar.gz
-rw-r--r--         836 2012/01/04 03:00:31 linux/kernel/v3.x/linux-3.0.15.tar.sign
-rw-r--r--    63812604 2012/01/04 03:00:31 linux/kernel/v3.x/linux-3.0.15.tar.xz

sent 59 bytes  received 80.19K bytes  12.35K bytes/sec
total size is 237.34M  speedup is 2957.66
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;你无需关注上面的规则代表什么意思，需要关注的重点是通过rsync可以向外提供文件列表并提供相应的下载。&lt;/p&gt;

&lt;p&gt;同样，你还可以根据路径，将rsync daemon上的文件拉取到本地实现下载的功能。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync --no-motd -avzP rsync://rsync.kernel.org/pub/linux/kernel/v3.x/linux-3.0.15.tar.bz2 /tmp
receiving incremental file list
linux-3.0.15.tar.bz2
     2834426   3%   300.51kB/s    0:40:22
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下面就来介绍下rsync daemon。&lt;/p&gt;

&lt;p&gt;rsync daemon是&amp;rdquo;rsync &amp;ndash;daemon&amp;rdquo;或再加上其他一些选项启动的，它会读取配置文件，默认是/etc/rsyncd.conf，并默认监听在873端口上，当外界有客户端对此端口发起连接请求，通过这个网络套接字就可以完成连接，以后与该客户端通信的所有数据都通过该网络套接字传输。&lt;/p&gt;

&lt;p&gt;rsync daemon的通信方式和传输通道与远程shell不同。远程shell连接的两端是通过管道完成通信和数据传输的，即使连接的一端是远程主机，当连接到目标端时，将在目标端上根据远程shell进程fork出rsync进程使其成为rsync server。而rsync daemon是事先在server端上运行好的rsync后台进程(根据启动选项，也可以设置为非后台进程)，它监听套接字等待client端的连接，连接建立后所有通信方式都是通过套接字完成的。&lt;/p&gt;

&lt;p&gt;注意，rsync中的server的概念从来就不代表是rsync daemon，server在rsync中只是一种通用称呼，只要不是发起rsync请求的client端，就是server端，你可以认为rsync daemon是一种特殊的server，其实daemon更应该称之为service。(之所以解释这一点，是避免各位初学的朋友在阅读man rsync过程中产生误解)&lt;/p&gt;

&lt;p&gt;以下是rsync client连接rsync daemon时的命令语法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Pull: rsync [OPTION...] [USER@]HOST::SRC... [DEST]
      rsync [OPTION...] rsync://[USER@]HOST[:PORT]/SRC... [DEST]
Push: rsync [OPTION...] SRC... [USER@]HOST::DEST
      rsync [OPTION...] SRC... rsync://[USER@]HOST[:PORT]/DEST
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;连接命令有两种类型，一种是rsync风格使用双冒号的&amp;rdquo;rsync user@host::src dest&amp;rdquo;，一种是url风格的&amp;rdquo;rsync://user@host:port/src dest&amp;rdquo;。对于rsync风格的连接命令，如果想要指定端口号，则需要使用选项&amp;rdquo;&amp;ndash;port&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;上述语法中，其中daemon端的路径，如user@host::src，它的src代表的是模块名，而不是真的文件系统中的路径。关于rsync中的模块，相信见了下面的配置文件就会知道是什么意思。&lt;/p&gt;

&lt;h4 id=&#34;5-2-daemon配置文件rsyncd-conf&#34;&gt;5.2 daemon配置文件rsyncd.conf&lt;/h4&gt;

&lt;p&gt;默认&amp;rdquo;rsync &amp;ndash;daemon&amp;rdquo;读取的配置文件为/etc/rsyncd.conf，有些版本的系统上可能该文件默认不存在。rsyncd.conf的配置见man rsyncd.conf。以下是部分内容：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# cat /etc/rsyncd.conf
# /etc/rsyncd: configuration file for rsync daemon mode

# See rsyncd.conf man page for more options.

# configuration example:

# uid = nobody
# gid = nobody
# use chroot = yes
# max connections = 4
# pid file = /var/run/rsyncd.pid
# exclude = lost+found/
# transfer logging = yes
# timeout = 900
# ignore nonreadable = yes
# dont compress   = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2

# [ftp1]
#        path = /home/ftp
#        comment = ftp export area
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在上述示例配置文件中，先定义了一些全局选项，然后定义了[ftp1]，这个用中括号包围的&amp;rdquo;[ftp1]&amp;ldquo;就是rsync中所谓的模块，ftp1为模块ID，必须保证唯一，每个模块中必须定义一项&amp;rdquo;path&amp;rdquo;，path定义的是该模块代表的路径，例如此示例文件中，如果想请求ftp1模块，则在客户端使用&amp;rdquo;rsync user@host::ftp1&amp;rdquo;，这表示访问user@host上的/home/ftp目录，如果要访问/home/ftp目录下的子目录www，则&amp;rdquo;rsync user@host::ftp1/www&amp;rdquo;。&lt;/p&gt;

&lt;p&gt;以下是常见的配置项，也算是一个配置示例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;######### 全局配置参数 ##########
port=888    # 指定rsync端口。默认873
uid = rsync # rsync服务的运行用户，默认是nobody，文件传输成功后属主将是这个uid
gid = rsync # rsync服务的运行组，默认是nobody，文件传输成功后属组将是这个gid
use chroot = no # rsync daemon在传输前是否切换到指定的path目录下，并将其监禁在内
max connections = 200 # 指定最大连接数量，0表示没有限制
timeout = 300         # 确保rsync服务器不会永远等待一个崩溃的客户端，0表示永远等待
motd file = /var/rsyncd/rsync.motd   # 客户端连接过来显示的消息
pid file = /var/run/rsyncd.pid       # 指定rsync daemon的pid文件
lock file = /var/run/rsync.lock      # 指定锁文件
log file = /var/log/rsyncd.log       # 指定rsync的日志文件，而不把日志发送给syslog
dont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2  # 指定哪些文件不用进行压缩传输

###########下面指定模块，并设定模块配置参数，可以创建多个模块###########
[longshuai]        # 模块ID
path = /longshuai/ # 指定该模块的路径，该参数必须指定。启动rsync服务前该目录必须存在。rsync请求访问模块本质就是访问该路径。
ignore errors      # 忽略某些IO错误信息
read only = false  # 指定该模块是否可读写，即能否上传文件，false表示可读写，true表示可读不可写。所有模块默认不可上传
write only = false # 指定该模式是否支持下载，设置为true表示客户端不能下载。所有模块默认可下载
list = false       # 客户端请求显示模块列表时，该模块是否显示出来，设置为false则该模块为隐藏模块。默认true
hosts allow = 10.0.0.0/24 # 指定允许连接到该模块的机器，多个ip用空格隔开或者设置区间
hosts deny = 0.0.0.0/32   # 指定不允许连接到该模块的机器
auth users = rsync_backup # 指定连接到该模块的用户列表，只有列表里的用户才能连接到模块，用户名和对应密码保存在secrts file中，
                          # 这里使用的不是系统用户，而是虚拟用户。不设置时，默认所有用户都能连接，但使用的是匿名连接
secrets file = /etc/rsyncd.passwd # 保存auth users用户列表的用户名和密码，每行包含一个username:passwd。由于&amp;quot;strict modes&amp;quot;
                                  # 默认为true，所以此文件要求非rsync daemon用户不可读写。只有启用了auth users该选项才有效。
[xiaofang]    # 以下定义的是第二个模块
path=/xiaofang/
read only = false
ignore errors
comment = anyone can access
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意：&lt;/p&gt;

&lt;p&gt;(1).客户端推到服务端时，文件的属主和属组是配置文件中指定的uid和gid。但是客户端从服务端拉的时候，文件的属主和属组是客户端正在操作rsync的用户身份，因为执行rsync程序的用户为当前用户。&lt;/p&gt;

&lt;p&gt;(2).auth users和secrets file这两行不是一定需要的，省略它们时将默认使用匿名连接。但是如果使用了它们，则secrets file的权限必须是600。客户端的密码文件也必须是600。&lt;/p&gt;

&lt;p&gt;(3).关于secrets file的权限，实际上并非一定是600，只要满足除了运行rsync daemon的用户可读即可。是否检查权限的设定是通过选项strict mode设置的，如果设置为false，则无需关注文件的权限。但默认是yes，即需要设置权限。&lt;/p&gt;

&lt;p&gt;配置完后，再就是提供模块相关目录、身份验证文件等。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# useradd -r -s /sbin/nologin rsync

[root@xuexi ~]# mkdir /{longshuai,xiaofang}

[root@xuexi ~]# chown -R rsync.rsync /{longshuai,xiaofang}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;提供模块longshuai身份验证文件，由于rsync daemon是以root身份运行的，所以要求身份验证文件对非root用户不可读写，所以设置为600权限。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# echo &amp;quot;rsync_backup:123456&amp;quot; &amp;gt;&amp;gt; /etc/rsyncd.passwd

[root@xuexi ~]# chmod 600 /etc/rsyncd.passwd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后启动rsync daemon，启动方式很简单。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync --daemon
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果是CentOS 7，则自带启动脚本。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# systemctl start rsyncd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看看该脚本的内容。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# cat /usr/lib/systemd/system/rsyncd.service
[Unit]
Description=fast remote file copy program daemon
ConditionPathExists=/etc/rsyncd.conf

[Service]
EnvironmentFile=/etc/sysconfig/rsyncd
ExecStart=/usr/bin/rsync --daemon --no-detach &amp;quot;$OPTIONS&amp;quot;

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到启动方法也仅仅只是多了一个&amp;rdquo;&amp;ndash;no-detach&amp;rdquo;，该选项表示rsync不将自己从终端上剥离。&lt;/p&gt;

&lt;p&gt;总之，启动好rysnc daemon后，它就监听在指定的端口上，等待客户端的连接。&lt;/p&gt;

&lt;p&gt;由于上述示例中的模块longshuai配置了身份验证功能，所以客户端连接时会询问密码。如果不想手动输入密码，则可以使用&amp;rdquo;&amp;ndash;password-file&amp;rdquo;选项提供密码文件，密码文件中只有第一行才是传递的密码，其余所有的行都会被自动忽略。&lt;/p&gt;

&lt;p&gt;例如在客户端上：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# echo &amp;quot;123456&amp;quot; &amp;gt; /tmp/rsync_passwd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后使用该&amp;rdquo;&amp;ndash;password-file&amp;rdquo;连接需要身份验证的longshuai模块。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# echo &amp;quot;123456&amp;quot; &amp;gt; /tmp/rsync_passwd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果需要访问模块中的某个文件，则：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync --list-only --port 888 rsync_backup@172.16.l0.6::longshuai/a/b --password-file=/tmp/rsync_passwd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还可以使用url格式语法：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync --list-only rsync://rsync_backup@172.16.l0.6:888/longshuai/a/b --password-file=/tmp/rsync_passwd
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;6-远程shell方式连接使用daemon&#34;&gt;6 远程shell方式连接使用daemon&lt;/h3&gt;

&lt;p&gt;在前文说了rsync有三种工作方式：本地同步模式、远程shell模式和rsync daemon模式。前两者是使用管道进行通信和传输数据的，后者是通过网络套接字进行通信和传输数据的，且rsync daemon要求在server端必须已经运行好rsync且监听在指定端口上。&lt;/p&gt;

&lt;p&gt;但rsync支持第4种工作方式：通过远程shell方式连接rsync daemon。也就是将第二种和第三种方式结合起来。虽然这种方式用的不多，但还是有必要稍微解释下，为你阅读rsync的man文档提供一些帮助。&lt;/p&gt;

&lt;p&gt;为了下面称呼的方便，暂且将通过远程shell连接使用daemon的方式成为&amp;rdquo;远程shell daemon&amp;rdquo;，当然，官方并没有这样的术语，仅仅只是本人在此为了方便而如此称呼。&lt;/p&gt;

&lt;p&gt;远程shell daemon的方式严格地说是&amp;rdquo;远程shell通信方式+使用rsync daemon的功能&amp;rdquo;。所以它的通信方式和远程shell是一样的，在客户端发起远程shell连接，在server端fork远程shell进程以启动rsync进程，但这个rsync进程是临时的rsync daemon，它只读取配置文件中client所请求的模块部分，且只读取模块部分中的path和身份认证相关内容，(也就是说不会将全局配置项和其它模块项加载到内存，该模块下的其他配置也不会生效)，当rsync操作完成，该rsync daemon就消逝并从内存中被清理。而且，远程shell daemon启动的临时daemon不会和已经在server端运行的rsync daemon冲突，它们可以并存。由于远程shell连接的最终目标是rsync模块，所以它只能使用rsync daemon语法。&lt;/p&gt;

&lt;p&gt;以下是语法格式：为了简洁，没有指定src还是dest，且以ssh这个远程shell为例。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rsync [options] --rsh=ssh auth_user@host::module

rsync [options] --rsh=&amp;quot;ssh -l ssh_user&amp;quot; auth_user@host::module

rsync [options] -e &amp;quot;ssh -l ssh_user&amp;quot; auth_user@host::module

rsync [options] -e &amp;quot;ssh -l ssh_user&amp;quot; rsync://auth_user@host/module
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;涉及了两个用户ssh_user和auth_user，由于使用的是远程shell通信方式，所以client要和server端建立ssh连接，ssh_user就是ssh连接server的用户。auth_user则是模块中的身份认证用户。如果不指定&amp;rdquo;ssh_user&amp;rdquo;，则默认将使用auth_user，但很多时候auth_user都只是一个虚拟用户，这样就建立不了ssh连接导致失败，所以建议明确指定ssh_user和auth_user。&lt;/p&gt;

&lt;p&gt;举个例子就能说明上面的一切。以下是server端配置文件/etc/rsyncd.conf中的一个模块配置，稍后将从client端使用远程shell方式请求该模块。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[tmpdir]
path=/tmp
auth users=lisi
secrets file=/tmp/lisi_passwd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当前server端是没有rsync daemon在运行的。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# netstat -tnl
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State     
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN    
tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN    
tcp6       0      0 :::22                   :::*                    LISTEN    
tcp6       0      0 ::1:25                  :::*                    LISTEN
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在客户端上使用以下命令：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@xuexi ~]# rsync --list-only -e &amp;quot;ssh -l root&amp;quot; lisi@172.16.10.6::tmpdir
root@172.16.10.6&#39;s password:

Password:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到要求输入两次密码，第一次密码是root@XXX的密码，即建立ssh连接使用的密码，只有建立了ssh连接，才能在server上启动临时rsync daemon。第二次输入的密码Password是&amp;rdquo;auth users=lisi&amp;rdquo;对应的密码。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;(Note: 本文转载自 &lt;a href=&#34;https://www.cnblogs.com/f-ck-need-u/p/7220009.html&#34; title=&#34;rsync基本命令和用法&#34;&gt;&lt;em&gt;这里&lt;/em&gt;&lt;/a&gt; )&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
